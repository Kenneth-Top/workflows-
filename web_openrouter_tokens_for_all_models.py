from playwright.sync_api import sync_playwright
import pandas as pd
import time
from datetime import datetime, timedelta
import re

# ================= æ‰¹é‡é…ç½®åŒºåŸŸ =================
# æ ¼å¼: ("æ¨¡å‹ID", "å¯é€‰:æ‰‹åŠ¨èµ·å§‹æ—¥æœŸYYYY-MM-DD")
# æ³¨æ„ï¼šç°åœ¨ä¸éœ€è¦å¡«æœ€é«˜å€¼çš„æ•°å­—äº†ï¼è„šæœ¬ä¼šè‡ªåŠ¨å»è¯»ï¼
MODELS_CONFIG = [
    ("moonshotai/kimi-k2-thinking", None),
    ("moonshotai/kimi-k2.5", None),
    ("deepseek/deepseek-v3.2", None),
    ("minimax/minimax-m2.1", None),
    ("x-ai/grok-4.1-fast", None),
    ("openai/gpt-5.1", None), 
    # ä½ å¯ä»¥ç»§ç»­æ·»åŠ æ›´å¤š...
]

OUTPUT_SUMMARY = f"summary_matrix.csv"
OUTPUT_STREAMLIT = f"streamlit_source.csv"
# ======================================================

def parse_tooltip_value(text):
    """
    å°† Tooltip é‡Œçš„ "97.5B", "800M", "10k" è½¬åŒ–ä¸ºæµ®ç‚¹æ•°
    """
    text = text.upper().replace(',', '')
    match = re.search(r'(\d+\.?\d*)\s*([BKM]?)', text)
    if not match:
        return 0.0
    
    val = float(match.group(1))
    unit = match.group(2)
    
    if unit == 'B': return val * 1_000_000_000 # ç»Ÿä¸€è½¬æ¢ä¸ºåŸºç¡€å•ä½æˆ–ä¿æŒ B ä¸ºå•ä½
    # è¿™é‡Œä¸ºäº†æ–¹ä¾¿ Excel é˜…è¯»ï¼Œæˆ‘ä»¬ç»Ÿä¸€è½¬æ¢ä¸º Billion (B) ä¸ºå•ä½
    if unit == 'B': return val
    if unit == 'M': return val / 1000
    if unit == 'K': return val / 1_000_000
    return val / 1_000_000_000 # æ— å•ä½é»˜è®¤ä¸ºä¸ªä½ï¼Œè½¬ä¸ºB

def scrape_and_calibrate(playwright_instance, model_id):
    url = f"https://openrouter.ai/{model_id}"
    print(f"\nğŸš€ [å¼€å§‹å¤„ç†] æ¨¡å‹: {model_id}")
    
    browser = playwright_instance.chromium.launch(headless=True) # è°ƒè¯•æ—¶æ”¹ False
    page = browser.new_page()
    page.goto(url)
    
    # 1. æŠ“å–åˆ›å»ºæ—¥æœŸ
    created_date_str = None
    try:
        page.wait_for_selector('body', timeout=10000)
        created_date_str = page.evaluate("""() => {
            const elements = document.querySelectorAll('div, span, p');
            for (const el of elements) {
                const match = el.innerText.match(/Created [A-Za-z]+ \d{1,2}, \d{4}/);
                if (match) return match[0];
            }
            return null;
        }""")
        if created_date_str:
            print(f"ğŸ“… è‡ªåŠ¨æ—¥æœŸ: {created_date_str}")
    except: pass

    # 2. æ»šåŠ¨åŠ è½½å›¾è¡¨
    try:
        page.wait_for_selector('path.recharts-rectangle', timeout=20000)
        print("âœ… å›¾è¡¨åŠ è½½ï¼Œæ»šåŠ¨æ¿€æ´»...")
        for i in range(6): 
            page.evaluate(f"window.scrollBy(0, 500)")
            time.sleep(0.5)
        time.sleep(2.0) 
    except:
        print(f"âŒ å›¾è¡¨åŠ è½½å¤±è´¥")
        browser.close()
        return None, None, None

    # 3. æå–åƒç´ æ•°æ® (å¸¦å»é‡)
    bars_data = page.evaluate("""() => {
        const paths = document.querySelectorAll('path.recharts-rectangle');
        const uniqueBars = new Map();
        const colorMap = {'#0088FE': 'Prompt', '#00C49F': 'Completion', '#FFBB28': 'Reasoning'};

        paths.forEach(p => {
            const height = parseFloat(p.getAttribute('height') || 0);
            const x = parseFloat(p.getAttribute('x') || 0);
            const fill = p.getAttribute('fill') || "";
            const colorHex = fill.toUpperCase();
            
            const style = window.getComputedStyle(p);
            if (style.opacity === '0' || style.visibility === 'hidden') return;
            if (height <= 1 || !colorMap[colorHex]) return;

            const key = `${Math.round(x)}_${colorHex}`;
            if (uniqueBars.has(key)) {
                if (height > uniqueBars.get(key).height_px) {
                    uniqueBars.set(key, {type: colorMap[colorHex], height_px: height, x_pos: x, dom_index: -1}); # indexç¨ååœ¨pyå¤„ç†
                }
            } else {
                uniqueBars.set(key, {type: colorMap[colorHex], height_px: height, x_pos: x, dom_index: -1});
            }
        });
        return Array.from(uniqueBars.values());
    }""")

    if not bars_data:
        browser.close()
        return None, None, None

    df = pd.DataFrame(bars_data)
    
    # ç­›é€‰åº•éƒ¨å›¾è¡¨
    max_y = df['x_pos'].max() # è¿™é‡Œæ²¡å–yï¼Œå‡è®¾æ•°æ®æ¯”è¾ƒå¹²å‡€ï¼Œæˆ–è€…æ²¿ç”¨ä¹‹å‰çš„é€»è¾‘
    df['x_pos'] = df['x_pos'].round(0)
    
    # ================= æ ¸å¿ƒå‡çº§ï¼šè‡ªåŠ¨æ ¡å‡† (Tooltip) =================
    # 1. æ‰¾åˆ° Prompt (è“è‰²) æœ€é«˜çš„é‚£æ ¹æŸ±å­çš„ x_pos
    if 'Prompt' in df['type'].values:
        max_bar = df[df['type'] == 'Prompt'].sort_values('height_px', ascending=False).iloc[0]
    else:
        max_bar = df.sort_values('height_px', ascending=False).iloc[0]
    
    target_x = max_bar['x_pos']
    max_px_height = max_bar['height_px']
    print(f"ğŸ” æ­£åœ¨æ‰§è¡Œè‡ªåŠ¨æ ¡å‡†... ç›®æ ‡ Xåæ ‡: {target_x}")

    # 2. Playwright æŸ¥æ‰¾å¯¹åº”çš„ DOM å…ƒç´ å¹¶æ‚¬åœ
    # æˆ‘ä»¬éœ€è¦é‡æ–°åœ¨é¡µé¢æ‰¾è¿™ä¸ªå…ƒç´ ï¼Œå› ä¸ºä¹‹å‰çš„ evaluate ä¼ å›çš„æ˜¯çº¯æ•°æ®
    try:
        # ä½¿ç”¨ CSS é€‰æ‹©å™¨å®šä½ï¼šæ‰¾åˆ° x å±æ€§æ¥è¿‘ target_x çš„ path
        # æ³¨æ„ï¼šSVG çš„ x å¯èƒ½æ˜¯å°æ•°ï¼Œæˆ‘ä»¬ç”¨æ¨¡ç³ŠåŒ¹é…é€»è¾‘ä¸å¤ªå¥½å†™ CSSï¼Œ
        # æœ€å¥½çš„åŠæ³•æ˜¯éå†æ‰€æœ‰ pathï¼Œæ‰¾åˆ° x åŒ¹é…çš„é‚£ä¸ªï¼Œç„¶å hover
        
        box = page.evaluate_handle(f"""(targetX) => {{
            const paths = document.querySelectorAll('path.recharts-rectangle');
            let target = null;
            let minDiff = 1.0;
            
            paths.forEach(p => {{
                const x = parseFloat(p.getAttribute('x') || 0);
                const fill = p.getAttribute('fill');
                // ç¡®ä¿æ˜¯è“è‰² Prompt æŸ±å­
                if (Math.abs(x - targetX) < minDiff && fill.toUpperCase() === '#0088FE') {{
                    target = p;
                    minDiff = Math.abs(x - targetX);
                }}
            }});
            return target;
        }}""", target_x)
        
        if box:
            box.hover()
            time.sleep(1) # ç­‰å¾… Tooltip å¼¹å‡º
            
            # 3. è¯»å– Tooltip å†…å®¹
            # OpenRouter Tooltip é€šå¸¸åœ¨ä¸€ä¸ª class ä¸º 'recharts-tooltip-wrapper' çš„ div é‡Œ
            tooltip_text = page.locator('.recharts-tooltip-wrapper').inner_text()
            print(f"ğŸ’¬ æ•è· Tooltip: {tooltip_text.replace(chr(10), ' | ')}")
            
            # è§£æ Prompt çš„æ•°å€¼
            # Tooltip æ ¼å¼é€šå¸¸æ˜¯: "Date \n Prompt 80B \n Completion..."
            # æˆ‘ä»¬ç”¨æ­£åˆ™æå– Prompt åé¢çš„æ•°å­—
            match = re.search(r'Prompt\s*([\d\.,]+[KMB]?)', tooltip_text, re.IGNORECASE)
            if match:
                raw_val = match.group(1)
                real_val = parse_tooltip_value(raw_val)
                scale_factor = real_val / max_px_height
                print(f"âš–ï¸ è‡ªåŠ¨æ ¡å‡†æˆåŠŸ! è¯»æ•°: {raw_val} -> ç³»æ•°: {scale_factor:.6f}")
            else:
                print("âš ï¸ Tooltip è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç³»æ•° 1.0")
                scale_factor = 1.0
        else:
            print("âš ï¸ æœªæ‰¾åˆ°ç›®æ ‡æŸ±å­ DOMï¼Œæ— æ³•æ‚¬åœã€‚")
            scale_factor = 1.0
            
    except Exception as e:
        print(f"âš ï¸ è‡ªåŠ¨æ ¡å‡†è¿‡ç¨‹æŠ¥é”™: {e}")
        scale_factor = 1.0

    browser.close()
    return df, created_date_str, scale_factor

def process_data(df, model_id, scale_factor, auto_date_str, manual_date):
    # 1. é€è§† & æ¸…æ´—
    df_pivot = df.pivot_table(index='x_pos', columns='type', values='height_px', aggfunc='max').fillna(0)
    df_pivot = df_pivot.sort_index()
    for col in ['Prompt', 'Completion', 'Reasoning']:
        if col not in df_pivot.columns: df_pivot[col] = 0.0
    
    # 2. åº”ç”¨æ¯”ä¾‹å°º
    df_final = df_pivot * scale_factor
    df_final['Total_Tokens'] = df_final.sum(axis=1)
    df_final = df_final.round(3)

    # 3. ç¡®å®šæ—¥æœŸ
    start_date = None
    if manual_date:
        try: start_date = pd.to_datetime(manual_date)
        except: pass
    if not start_date and auto_date_str:
        try:
            clean = auto_date_str.replace("Created ", "").strip()
            start_date = datetime.strptime(clean, "%b %d, %Y")
        except: pass
    if not start_date: start_date = datetime.now()

    # 4. ç”Ÿæˆå®Œæ•´æ—¥æœŸåˆ—
    df_final['Date'] = [start_date + timedelta(days=i) for i in range(len(df_final))]
    df_final['Day_Index'] = range(len(df_final)) # T+0, T+1...
    
    # 5. ç”Ÿæˆä¸¤ä¸ªç‰ˆæœ¬çš„è¾“å‡º
    
    # --- A. å®½è¡¨æ•°æ® (T+N æ±‡æ€») ---
    summary_row = {'Model': model_id, 'Start_Date': start_date.strftime('%Y-%m-%d')}
    targets = [0, 1, 2, 3, 4, 5, 6, 7, 10, 14, 30, 60]
    
    for t in targets:
        # ä¸¥æ ¼ä½¿ç”¨ilocæŸ¥æ‰¾ï¼Œå¦‚æœ index è¶…å‡ºèŒƒå›´åˆ™ä¸ºç©º
        if t < len(df_final):
            val = df_final.iloc[t]['Total_Tokens']
            summary_row[f"T+{t}"] = val
        else:
            summary_row[f"T+{t}"] = None
            
    # --- B. é•¿è¡¨æ•°æ® (Streamlit ç”¨) ---
    # åŒ…å«æ¯ä¸€å¤©çš„æ•°æ®ï¼ŒåŠ ä¸Š Latest æ ‡è®°
    streamlit_df = df_final.copy()
    streamlit_df['Model'] = model_id
    streamlit_df['Is_Latest'] = False
    streamlit_df.iloc[-1, streamlit_df.columns.get_loc('Is_Latest')] = True # æ ‡è®°æœ€åä¸€è¡Œ
    
    # é‡å‘½ååˆ—ä»¥ç¬¦åˆ Streamlit ä¹ æƒ¯
    streamlit_df = streamlit_df[['Date', 'Model', 'Total_Tokens', 'Day_Index', 'Is_Latest', 'Prompt', 'Completion', 'Reasoning']]

    return summary_row, streamlit_df

def run():
    all_summaries = []
    all_streamlit_data = []

    with sync_playwright() as p:
        for model_id, manual_date in MODELS_CONFIG:
            try:
                # çˆ¬å– + è‡ªåŠ¨è·å–ç³»æ•°
                df_raw, auto_date, scale = scrape_and_calibrate(p, model_id)
                
                if df_raw is not None:
                    # å¤„ç†æ•°æ®
                    summ_row, st_df = process_data(df_raw, model_id, scale, auto_date, manual_date)
                    all_summaries.append(summ_row)
                    all_streamlit_data.append(st_df)
            except Exception as e:
                print(f"âŒ å¤„ç† {model_id} å¼‚å¸¸: {e}")

    # ä¿å­˜å®½è¡¨ (Excel/CSV)
    if all_summaries:
        df_sum = pd.DataFrame(all_summaries)
        # æ’åºæ¯ä¸€åˆ—
        cols = ['Model', 'Start_Date'] + [f"T+{d}" for d in [0, 1, 2, 3, 4, 5, 6, 7, 10, 14, 30, 60]]
        cols = [c for c in cols if c in df_sum.columns]
        df_sum = df_sum[cols]
        df_sum.to_csv(OUTPUT_SUMMARY, index=False)
        print(f"\nâœ… å®½è¡¨å·²ä¿å­˜: {OUTPUT_SUMMARY}")

    # ä¿å­˜é•¿è¡¨ (Streamlit)
    if all_streamlit_data:
        df_st = pd.concat(all_streamlit_data)
        df_st.to_csv(OUTPUT_STREAMLIT, index=False)
        print(f"âœ… Streamlitæºæ•°æ®å·²ä¿å­˜: {OUTPUT_STREAMLIT}")

if __name__ == "__main__":
    run()