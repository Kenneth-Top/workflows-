name: Daily Data Scrape

on:
  schedule:
    # æ¯å¤© UTC æ—¶é—´ 00:00 è¿è¡Œ (åŒ—äº¬æ—¶é—´æ—©ä¸Š 8:00)
    - cron: '0 0 * * *'
  workflow_dispatch: # å…è®¸æ‰‹åŠ¨ç‚¹å‡»æŒ‰é’®è§¦å‘

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest
    
    steps:
      - name: Check out repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          pip install pandas openpyxl playwright plotly streamlit
          playwright install chromium

      - name: Run Scraper Script
        run: python web_openrouter_tokens_for_all_models.py  # <--- æŠŠè¿™é‡Œæ”¹æˆä½ çˆ¬è™«è„šæœ¬çš„æ–‡ä»¶å

      - name: Commit and Push if changes
        run: |
          git config --global user.name "GitHub Action"
          git config --global user.email "action@github.com"
          git add latest_summary.csv
          git commit -m "ğŸš€ Auto-update data [skip ci]" || echo "No changes to commit"
          git push
