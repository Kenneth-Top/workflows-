import streamlit as st
import pandas as pd
import altair as alt
import os
import io
import json

# === 1. åŸºç¡€é…ç½® ===
st.set_page_config(page_title="LLM æ•°æ®çœ‹æ¿", layout="wide")
DATA_FILE = "history_database.csv"
PRICING_FILE = "openrouter_pricing_provider_records.csv"
BENCHMARK_FILE = "openrouter_benchmark_records.csv"
LMARENA_FILE = "lmarena_leaderboard_records.csv"

# é¡µé¢æ ‡é¢˜
st.title("LLM æ•°æ®çœ‹æ¿")

# å®šä¹‰é¡µé¢åç§°å¸¸é‡
NAV_AI_QUERY = "AI æŸ¥è¯¢"
NAV_DAILY_BRIEF = "æ¯æ—¥ç®€æŠ¥"
NAV_TN_DAILY = "T+N æ—¥ç”¨é‡å¯¹æ¯”"
NAV_CUMULATIVE_COMPARE = "ç´¯è®¡ç”¨é‡å¯¹æ¯”"
NAV_DETAIL_DAILY = "å•æ¨¡å‹ç”¨é‡"
NAV_RAW_DATA = "æ•°æ®å¯¼å‡º"
NAV_PRICING = "ä¾›åº”å•†å®šä»·"
NAV_BENCHMARK = "åŸºå‡†æµ‹è¯•"
NAV_SINGLE_MODEL = "å•æ¨¡å‹æ·±åº¦åˆ†æ"

# === 2. å·¥å…·å‡½æ•° ===

def is_reasoning_model(model_name: str) -> bool:
    """åŸºäºæ¨¡å‹å‘½åè§„åˆ™è¿›è¡Œç²—ç•¥åˆ¤æ–­æ˜¯å¦ä¸ºæ·±åº¦æ¨ç†æ¨¡å‹"""
    if not isinstance(model_name, str): return False
    name_lower = model_name.lower()
    reasoning_keywords = ['reasoning', 'o1', 'o3', 'r1', 'qwq']
    for kw in reasoning_keywords:
        if kw in name_lower:
            return True
    return False

import re as _re_global

def _tokenize_model_name(name: str) -> set:
    """å°†æ¨¡å‹åæ‹†ä¸º token é›†åˆï¼Œç”¨äºæ¨¡ç³ŠåŒ¹é…"""
    n = name.lower()
    # å»æ‰å‚å•†å‰ç¼€
    if '/' in n:
        n = n.split('/')[-1]
    # å»æ‰æ‹¬å·å†…ä¿®é¥°è¯ï¼Œå¦‚ (Reasoning), (Oct '24), (Non-reasoning)
    n = _re_global.sub(r'\s*\(.*?\)', '', n)
    # æŒ‰ ç©ºæ ¼ã€æ¨ªçº¿ã€ä¸‹åˆ’çº¿ åˆ†å‰²
    tokens = set(_re_global.split(r'[\s\-_]+', n.strip()))
    tokens.discard('')
    return tokens

def _jaccard_similarity(set_a: set, set_b: set) -> float:
    """è®¡ç®—ä¸¤ä¸ªé›†åˆçš„ Jaccard ç›¸ä¼¼åº¦"""
    if not set_a or not set_b:
        return 0.0
    intersection = set_a & set_b
    union = set_a | set_b
    return len(intersection) / len(union)

def normalize_model_name(name: str) -> str:
    """ç»Ÿä¸€æ¶ˆé™¤å‚å•†å‰ç¼€å’Œæ— ç”¨çš„å¤§å°å†™ï¼Œä½¿ä¸åŒæ•°æ®æºä¸­çš„åŒæ¬¾æ¨¡å‹èƒ½åˆå¹¶"""
    if not isinstance(name, str): return str(name)
    n = name.lower()
    # ç§»é™¤è¯¸å¦‚ 'anthropic/', 'google/' ç­‰å‰ç¼€
    if '/' in n:
        n = n.split('/')[-1]
    
    # ä»…ä¿ç•™æç«¯ç‰¹ä¾‹çš„ç¡¬æ˜ å°„ï¼ˆå®Œå…¨ä¸åŒå‘½åçš„æƒ…å†µï¼‰
    mapping = {
        'deepseek v3': 'deepseek-chat',
        'deepseek-v3': 'deepseek-chat',
    }
    
    for key, val in mapping.items():
        if key in n:
            return val
            
    # å»é™¤å¤šä½™æ‹¬å·å¦‚ (Reasoning) ç­‰å¹²æ‰°è¯ï¼Œä¿ç•™æ ¸å¿ƒ slug
    n = _re_global.sub(r'\s*\(.*?\)', '', n).strip()
    n = n.replace(' ', '-')
    return n

def fuzzy_match_model(target_norm: str, candidate_names: list, threshold: float = 0.55) -> list:
    """åœ¨å€™é€‰æ¨¡å‹ååˆ—è¡¨ä¸­ï¼Œç”¨ Token åŒ– Jaccard åŒ¹é…æ‰¾å‡ºä¸ target_norm ç›¸ä¼¼çš„åå­—"""
    target_tokens = _tokenize_model_name(target_norm)
    matched = []
    for cand in candidate_names:
        cand_tokens = _tokenize_model_name(cand)
        sim = _jaccard_similarity(target_tokens, cand_tokens)
        if sim >= threshold:
            matched.append(cand)
    return matched

@st.cache_data(ttl=600)
def load_data():
    if not os.path.exists(DATA_FILE):
        return None, f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶ `{DATA_FILE}`ï¼Œè¯·ç­‰å¾…çˆ¬è™«è¿è¡Œã€‚"
    try:
        # Load Token Data
        df = pd.read_csv(DATA_FILE)
        if df.empty: return None, "CSV æ–‡ä»¶ä¸ºç©º"
        df['Date'] = pd.to_datetime(df['Date'])
        
        # åç§°æ¸…æ´—ï¼šå»æ‰ '/' å‰é¢çš„å‚å•†å
        df['Display_Name'] = df['Model'].apply(lambda x: x.split('/')[-1] if '/' in x else x)
        
        return df, None
    except Exception as e:
        return None, str(e)

@st.cache_data(ttl=600)
def load_pricing_data():
    if not os.path.exists(PRICING_FILE):
        return None
    try:
        df_price = pd.read_csv(PRICING_FILE)
        df_price['Date'] = pd.to_datetime(df_price['Date'])
        return df_price
    except Exception:
        return None

@st.cache_data(ttl=600)
def load_benchmark_data():
    if not os.path.exists(BENCHMARK_FILE):
        return None
    try:
        df_bench = pd.read_csv(BENCHMARK_FILE)
        df_bench['Date'] = pd.to_datetime(df_bench['Date'])
        return df_bench
    except Exception:
        return None

@st.cache_data(ttl=600)
def load_lmarena_data():
    if not os.path.exists(LMARENA_FILE): return None
    try:
        df = pd.read_csv(LMARENA_FILE)
        df['Date'] = pd.to_datetime(df['Date'])
        return df
    except Exception:
        return None

# Excel/CSV æ™ºèƒ½å¯¼å‡ºå‡½æ•°
def get_dataset_download(df, filename_prefix):
    try:
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='Sheet1')
        data = output.getvalue()
        file_name = f"{filename_prefix}.xlsx"
        mime = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        label = "ğŸ“¥ ä¸‹è½½ Excel æ–‡ä»¶ (.xlsx)"
    except ImportError:
        data = df.to_csv(index=False).encode('utf-8-sig')
        file_name = f"{filename_prefix}.csv"
        mime = "text/csv"
        label = "ğŸ“¥ ä¸‹è½½ CSV æ–‡ä»¶ (Excelå…¼å®¹)"
    
    return data, file_name, mime, label

df, error = load_data()
df_price = load_pricing_data()
df_bench = load_benchmark_data()
df_lmarena = load_lmarena_data()

if error and not (df_price is not None or df_bench is not None):
    st.error(error)
    st.stop()

# === 3. ä¾§è¾¹æ å¯¼èˆª ===
st.sidebar.title("å¯¼èˆª")
page = st.sidebar.radio("é€‰æ‹©åˆ†æè§†å›¾", [
    NAV_AI_QUERY,
    NAV_DAILY_BRIEF,
    NAV_SINGLE_MODEL,
    NAV_TN_DAILY,
    NAV_CUMULATIVE_COMPARE,
    NAV_DETAIL_DAILY,
    NAV_PRICING,
    NAV_BENCHMARK,
    NAV_RAW_DATA
])

all_model_names = df['Display_Name'].unique() if df is not None else []
all_pricing_models = df_price['Model'].unique() if df_price is not None else []
all_benchmark_models = [c for c in df_bench.columns if c not in ['Date', 'Metric']] if df_bench is not None else []

# æ•°æ®æ¦‚è§ˆé¢æ¿
st.sidebar.divider()
st.sidebar.markdown("#### æ•°æ®æ¦‚è§ˆ")
if df is not None:
    st.sidebar.metric("è¿½è¸ªæ¨¡å‹æ•°", len(all_model_names))
    st.sidebar.caption(f"æ•°æ®åŒºé—´: {df['Date'].min().strftime('%Y-%m-%d')} ~ {df['Date'].max().strftime('%Y-%m-%d')}")
if df_price is not None:
    st.sidebar.metric("å®šä»·æ¨¡å‹æ•°", len(all_pricing_models))
    st.sidebar.caption(f"å®šä»·æ›´æ–°è‡³: {df_price['Date'].max().strftime('%Y-%m-%d')}")
if df_bench is not None:
    st.sidebar.metric("è·‘åˆ†æ¨¡å‹æ•°", len(all_benchmark_models))
    st.sidebar.caption(f"è·‘åˆ†æ›´æ–°è‡³: {df_bench['Date'].max().strftime('%Y-%m-%d')}")
if df_lmarena is not None:
    st.sidebar.metric("LMARENA æ¨¡å‹æ•°", df_lmarena['Model'].nunique())
    st.sidebar.caption(f"LMARENA æ›´æ–°è‡³: {df_lmarena['Date'].max().strftime('%Y-%m-%d')}")

# ========================================================
# é¡µé¢ 0: AI æ™ºèƒ½æŸ¥è¯¢
# ========================================================
if page == NAV_AI_QUERY:
    st.subheader("AI æ•°æ®åˆ†æåŠ©æ‰‹")
    
    MODEL_OPTIONS = {
        "DeepSeek V3 (é«˜æ€§ä»·æ¯”)": "deepseek/deepseek-chat",
        "Claude Sonnet 4 (å¼ºæ¨ç†)": "anthropic/claude-sonnet-4",
        "GPT-4.1 (å‡è¡¡)": "openai/gpt-4.1",
        "Gemini 2.5 Flash (å¿«é€Ÿ)": "google/gemini-2.5-flash-preview",
    }
    selected_model_label = st.selectbox("é€‰æ‹© AI æ¨¡å‹:", list(MODEL_OPTIONS.keys()), index=0)
    AI_MODEL = MODEL_OPTIONS[selected_model_label]
    st.caption(f"å½“å‰æ¨¡å‹: `{AI_MODEL}`")
    
    # API Key é…ç½®
    api_key = os.environ.get("OPENROUTER_API_KEY", "") or st.secrets.get("OPENROUTER_API_KEY", "")
    if not api_key:
        api_key = st.text_input("è¯·è¾“å…¥ OpenRouter API Key:", type="password", 
                                help="åœ¨ https://openrouter.ai/keys è·å–ã€‚ä¹Ÿå¯é€šè¿‡ Streamlit Secrets æˆ–ç¯å¢ƒå˜é‡é…ç½®ã€‚")
    
    if not api_key:
        st.warning("è¯·å…ˆé…ç½® OpenRouter API Keyã€‚")
    else:
        # æ„å»ºæ•°æ®åº“ä¸Šä¸‹æ–‡æ‘˜è¦
        @st.cache_data(ttl=600)
        def build_db_context(_df, _df_price, _df_bench, _df_lmarena):
            context_parts = []
            
            if _df is not None and not _df.empty:
                # æä¾›æ‰€æœ‰æ¨¡å‹ååˆ—è¡¨å¸®åŠ© AI åšæ¨¡ç³ŠåŒ¹é…
                all_models = _df['Model'].unique().tolist()
                display_names = _df['Display_Name'].unique().tolist() if 'Display_Name' in _df.columns else []
                context_parts.append(f"""### Token æ¶ˆè€—æ•°æ® (å˜é‡å: df)
- åˆ—: Date, Model, Prompt, Completion, Reasoning, Total_Tokens, Display_Name
- è®°å½•æ•°: {len(_df)}, æ—¥æœŸèŒƒå›´: {_df['Date'].min().strftime('%Y-%m-%d')} ~ {_df['Date'].max().strftime('%Y-%m-%d')}
- Token å•ä½: Billion (10äº¿)
- å…¨éƒ¨æ¨¡å‹åˆ—è¡¨(Modelåˆ—): {', '.join(all_models[:30])}
- æ˜¾ç¤ºååˆ—è¡¨(Display_Nameåˆ—): {', '.join(display_names[:30])}""")

            if _df_price is not None and not _df_price.empty:
                price_models = _df_price['Model'].unique().tolist()
                context_parts.append(f"""### å®šä»·æ•°æ® (å˜é‡å: df_price)
- åˆ—: Date, Model, Provider, Input_Price_1M, Output_Price_1M, Cache_Hit_Rate
- è®°å½•æ•°: {len(_df_price)}, æ—¥æœŸæ•°: {_df_price['Date'].dt.strftime('%Y-%m-%d').nunique()}
- ä»·æ ¼å•ä½: $/1M Tokens
- æ¨¡å‹åˆ—è¡¨(å‰30): {', '.join(price_models[:30])}""")

            if _df_bench is not None and not _df_bench.empty:
                context_parts.append(f"""### Benchmark è·‘åˆ† (å˜é‡å: df_bench)
- ç»“æ„: å®½è¡¨ï¼Œæ¯è¡Œæ˜¯ä¸€ä¸ª Metricï¼Œæ¯åˆ—æ˜¯ä¸€ä¸ªæ¨¡å‹å
- Metric: {', '.join(_df_bench['Metric'].unique()[:8])}
- æ¨¡å‹æ•°: {len([c for c in _df_bench.columns if c not in ['Date','Metric']])}""")

            if _df_lmarena is not None and not _df_lmarena.empty:
                score_cols = [c for c in _df_lmarena.columns if c.startswith('Score_')]
                rank_cols = [c for c in _df_lmarena.columns if c.startswith('Rank_')]
                context_parts.append(f"""### Arena ç«æŠ€æ’è¡Œ (å˜é‡å: df_lmarena)
- æ•°æ®æº: arena.ai (åŸ LMARENA)
- 8 ä¸ª ELO æ’è¡Œæ¦œ: {', '.join(c.replace('Score_','') for c in score_cols)}
- Arena Overview æ’åç»´åº¦: {', '.join(c.replace('Rank_','') for c in rank_cols)}
- æ¯ä¸ª Score åˆ—å¯¹åº” Votes åˆ— (å¦‚ Score_text â†’ Votes_text)
- æ¨¡å‹æ•°: {_df_lmarena['Model'].nunique()}
- æ¨¡å‹ç¤ºä¾‹: {', '.join(_df_lmarena['Model'].unique().tolist()[:15])}""")
            
            return '\n\n'.join(context_parts)
        
        db_context = build_db_context(df, df_price, df_bench, df_lmarena)
        
        SYSTEM_PROMPT = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ LLM è¡Œä¸šæŠ•ç ”åˆ†æå¸ˆï¼ŒæœåŠ¡äºæœºæ„æŠ•èµ„è€…ã€‚ä½ çš„æ ¸å¿ƒä»»åŠ¡æ˜¯ç”¨**æ•°æ®é©±åŠ¨çš„å¯è§†åŒ–å›¾è¡¨**å›ç­”é—®é¢˜ã€‚

## æ•°æ®åº“

{db_context}

## è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå®ˆï¼‰

1. **æ–‡å­—éƒ¨åˆ†**ï¼šç”¨ 3-5 å¥è¯ç»™å‡ºæ ¸å¿ƒç»“è®ºï¼ŒåƒæŠ•ç ”æŠ¥å‘Šæ‘˜è¦ä¸€æ ·ç®€æ´ã€‚æä¾›å…³é”®æ•°æ®+æ´å¯Ÿã€‚
2. **ä»£ç éƒ¨åˆ†**ï¼šå¿…é¡»ç”Ÿæˆä¸€ä¸ª ```python``` ä»£ç å—ï¼ŒåŒ…å«**è‡³å°‘ 1 ä¸ªå›¾è¡¨**ã€‚ä½ çš„ä¸»è¦ä»·å€¼åœ¨äºå¯è§†åŒ–ï¼Œä¸æ˜¯æ–‡å­—ã€‚

## å¯è§†åŒ–æŒ‡å—ï¼ˆæŠ•ç ”é£æ ¼ï¼‰

ä½ ç”Ÿæˆçš„ä»£ç ä¼šè¢« exec() ç›´æ¥æ‰§è¡Œï¼Œå˜é‡å·²é¢„åŠ è½½: `df, df_price, df_bench, df_lmarena, st, alt, pd`

### å›¾è¡¨è§„èŒƒ
- ä½¿ç”¨ `st.altair_chart(chart, use_container_width=True)` å±•ç¤º Altair å›¾è¡¨
- ç”¨ `st.dataframe()` å±•ç¤ºè¾…åŠ©æ•°æ®è¡¨æ ¼ï¼ˆå¯é€‰ï¼Œæ”¾åœ¨å›¾è¡¨ä¹‹åï¼‰
- é…è‰²æ–¹æ¡ˆï¼šä½¿ç”¨ `alt.Scale(scheme='tableau20')` æˆ–æ‰‹åŠ¨æŒ‡å®šä¸“ä¸šé…è‰²
- æ ‡é¢˜ç”¨ä¸­æ–‡ï¼Œå­—å·è®¾ä¸º 16ï¼ˆ`.properties(title=alt.Title('æ ‡é¢˜', fontSize=16))`ï¼‰
- å›¾è¡¨é«˜åº¦å»ºè®® 350-450px

### å…¸å‹å›¾è¡¨ç±»å‹
- **ç”¨é‡è¶‹åŠ¿** â†’ æŠ˜çº¿å›¾ (line chart)ï¼ŒX=æ—¥æœŸ, Y=Tokené‡, Color=æ¨¡å‹
- **ä»·æ ¼å¯¹æ¯”** â†’ åˆ†ç»„æŸ±çŠ¶å›¾ï¼ŒX=æ¨¡å‹/ä¾›åº”å•†, Y=ä»·æ ¼, Color=Input/Output
- **Arenaæ’å** â†’ æ°´å¹³æŸ±çŠ¶å›¾ï¼ŒY=æ¨¡å‹, X=æ’åï¼ˆå‡åºï¼Œ1=æœ€å¥½ï¼‰
- **å¤šç»´é›·è¾¾** â†’ å¦‚æœéœ€è¦å¯¹æ¯”å¤šç»´åº¦ï¼Œç”¨åˆ†ç»„æŸ±çŠ¶å›¾æ›¿ä»£

### ä»£ç å®‰å…¨è§„åˆ™
- **ç±»å‹å®‰å…¨**ï¼šå¯¹æ‰€æœ‰åˆ—ä½¿ç”¨æ“ä½œå‰**å…ˆç¡®ä¿ç±»å‹æ­£ç¡®**
  - æ•°å€¼åˆ—: `pd.to_numeric(col, errors='coerce')`
  - å­—ç¬¦ä¸²æ“ä½œå‰: `col = col.astype(str)`
  - æ—¥æœŸåˆ—å·²æ˜¯ datetimeï¼Œæ— éœ€è½¬æ¢
- **æ¨¡ç³ŠåŒ¹é…**: 
  - `df[df['Model'].astype(str).str.contains('å…³é”®è¯', case=False, na=False)]`
  - ä¸åŒæ•°æ®æºå‘½åä¸åŒï¼ˆToken: 'deepseek/deepseek-r1'ï¼ŒArena: 'deepseek-r1'ï¼‰ï¼Œè¦**åˆ†åˆ«**åœ¨å„ DataFrame ä¸­åŒ¹é…
- **é˜²ç©ºæ•°æ®**: åŒ¹é…åå…ˆæ£€æŸ¥ `if len(matched) > 0:` å†ç»˜å›¾ï¼Œå¦åˆ™ `st.info('è¯¥æ•°æ®æºä¸­æœªæ‰¾åˆ°åŒ¹é…æ¨¡å‹')`
- **åªå†™ä¸€ä¸ªä»£ç å—**ï¼ŒåŒ…å«æ‰€æœ‰å›¾è¡¨å’Œè¡¨æ ¼

## åˆ†æè§†è§’

ä»æŠ•ç ”è§’åº¦åˆ†æï¼Œå…³æ³¨ï¼š
- **å¸‚åœºæ ¼å±€**ï¼šæ¨¡å‹é—´ç«äº‰æ€åŠ¿ã€ä»½é¢å˜åŒ–
- **æ€§ä»·æ¯”**ï¼šæ€§èƒ½/ä»·æ ¼æ¯”ï¼ŒåŒæ¡£ä½æ¨¡å‹å¯¹æ¯”
- **è¶‹åŠ¿**ï¼šç”¨é‡å¢é•¿/ä¸‹é™è¶‹åŠ¿ï¼Œä»·æ ¼å˜åŠ¨æ–¹å‘
- **å®šä»·**: Input_Price_1M å’Œ Output_Price_1M å•ä½ä¸º $/1M Tokens"""

        # åˆå§‹åŒ–èŠå¤©å†å²
        if "ai_messages" not in st.session_state:
            st.session_state.ai_messages = []
        
        # ç”¨äº exec çš„å‘½åç©ºé—´
        import numpy as np
        exec_namespace = {
            "df": df, "df_price": df_price, "df_bench": df_bench, "df_lmarena": df_lmarena,
            "st": st, "alt": alt, "pd": pd, "np": np, "os": os,
        }
        
        # è¾…åŠ©å‡½æ•°ï¼šä» AI å›å¤ä¸­åˆ†ç¦»æ–‡å­—å’Œä»£ç 
        def split_reply(reply):
            import re as _re
            code_blocks = _re.findall(r'```python\s*\n(.*?)```', reply, _re.DOTALL)
            # å»æ‰ä»£ç å—ï¼Œåªç•™æ–‡å­—
            text_only = _re.sub(r'```python\s*\n.*?```', '', reply, flags=_re.DOTALL).strip()
            return text_only, code_blocks[0] if code_blocks else None
        
        def safe_exec(code, ns):
            """å®‰å…¨æ‰§è¡Œä»£ç ï¼Œé¢„å¤„ç†å¸¸è§ç±»å‹é—®é¢˜"""
            # é¢„å¤„ç†: ç¡®ä¿æ‰€æœ‰ DataFrame çš„ Model åˆ—ä¸º str ç±»å‹
            for key in ['df', 'df_price', 'df_lmarena']:
                frame = ns.get(key)
                if frame is not None and 'Model' in frame.columns:
                    frame = frame.copy()
                    frame['Model'] = frame['Model'].astype(str)
                    ns[key] = frame
            exec(code, ns)
        
        # æ˜¾ç¤ºå†å²å¯¹è¯
        for msg in st.session_state.ai_messages:
            with st.chat_message(msg["role"]):
                if msg["role"] == "assistant":
                    text_part, code = split_reply(msg["content"])
                    st.markdown(text_part)
                    if code:
                        try:
                            safe_exec(code, exec_namespace)
                        except Exception:
                            pass
                else:
                    st.markdown(msg["content"])
        
        # ç”¨æˆ·è¾“å…¥
        user_query = st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜ï¼Œä¾‹å¦‚: 'glm æœ¬æœˆçš„ç”¨é‡è¶‹åŠ¿å’Œç«æŠ€åœºè¡¨ç°'")
        
        if user_query:
            st.session_state.ai_messages.append({"role": "user", "content": user_query})
            with st.chat_message("user"):
                st.markdown(user_query)
            
            # æ„å»º API è¯·æ±‚
            messages = [{"role": "system", "content": SYSTEM_PROMPT}]
            # åªä¼ æœ€è¿‘ 6 è½®å¯¹è¯ä½œä¸ºä¸Šä¸‹æ–‡
            for msg in st.session_state.ai_messages[-12:]:
                messages.append({"role": msg["role"], "content": msg["content"]})
            
            with st.chat_message("assistant"):
                with st.spinner("AI æ­£åœ¨åˆ†ææ•°æ®..."):
                    try:
                        import requests as _req
                        resp = _req.post(
                            "https://openrouter.ai/api/v1/chat/completions",
                            headers={
                                "Authorization": f"Bearer {api_key}",
                                "Content-Type": "application/json"
                            },
                            json={
                                "model": AI_MODEL,
                                "messages": messages,
                                "max_tokens": 4000,
                                "temperature": 0.3
                            },
                            timeout=60
                        )
                        resp.raise_for_status()
                        result = resp.json()
                        ai_reply = result['choices'][0]['message']['content']
                    except Exception as e:
                        ai_reply = f"æŸ¥è¯¢å¤±è´¥: {str(e)}"
                
                # åˆ†ç¦»æ–‡å­—å’Œä»£ç ï¼Œåªæ˜¾ç¤ºæ–‡å­—ï¼Œä»£ç ç›´æ¥æ‰§è¡Œ
                text_part, chart_code = split_reply(ai_reply)
                st.markdown(text_part)
                
                if chart_code:
                    try:
                        safe_exec(chart_code, exec_namespace)
                    except Exception as e:
                        st.warning(f"å›¾è¡¨æ¸²æŸ“å‡ºé”™ï¼Œæ­£åœ¨å°è¯•ä¿®å¤...")
                        with st.expander("æŸ¥çœ‹é”™è¯¯è¯¦æƒ…", expanded=False):
                            st.code(f"é”™è¯¯: {e}\n\nåŸå§‹ä»£ç :\n{chart_code}", language="python")
                
                st.session_state.ai_messages.append({
                    "role": "assistant", 
                    "content": ai_reply,
                })
        
        # æ¸…ç©ºå¯¹è¯æŒ‰é’®
        if st.session_state.ai_messages:
            if st.button("æ¸…ç©ºå¯¹è¯å†å²"):
                st.session_state.ai_messages = []
                st.rerun()

# ========================================================
# é¡µé¢ 1: T+N æ¨ªå‘å¯¹æ¯” (æ¯æ—¥æ¶ˆè€—)
# ========================================================
elif page == NAV_TN_DAILY:
    st.subheader("æ¨¡å‹å¢é•¿æ›²çº¿å¯¹æ¯” (T+N æ¯æ—¥æ¶ˆè€—)")
    st.info("æ¨ªè½´ï¼šä¸Šçº¿å¤©æ•° | çºµè½´ï¼šå½“æ—¥ Token æ¶ˆè€—é‡")

    selected_names = st.multiselect(
        "é€‰æ‹©è¦å¯¹æ¯”çš„æ¨¡å‹:", 
        all_model_names, 
        default=all_model_names[:1] 
    )
    
    if selected_names:
        tn_data = []
        standard_ticks = [0, 1, 2, 3, 4, 5, 6, 7, 10, 14, 30, 60]
        final_tick_values = set(standard_ticks)
        
        max_days_global = 0

        for name in selected_names:
            m_df = df[df['Display_Name'] == name].sort_values('Date')
            if m_df.empty: continue
            
            start_date = m_df.iloc[0]['Date']
            st.caption(f"ğŸ“… **{name}** æ”¶å½•èµ·å§‹æ—¥: {start_date.strftime('%Y-%m-%d')}")
            
            if len(m_df) > 1: m_df = m_df.iloc[:-1]

            latest_date = m_df.iloc[-1]['Date']
            latest_day_diff = (latest_date - start_date).days
            final_tick_values.add(latest_day_diff)
            
            if latest_day_diff > max_days_global:
                max_days_global = latest_day_diff

            for _, row in m_df.iterrows():
                day_diff = (row['Date'] - start_date).days
                if day_diff in standard_ticks or day_diff == latest_day_diff:
                    tn_data.append({
                        'Model': name,
                        'Days_Since_Start': day_diff,
                        'Total_Tokens': row['Total_Tokens'],
                        'Label': f"T+{day_diff}" if day_diff != latest_day_diff else f"Latest (T+{day_diff})",
                        'Real_Date': row['Date'].strftime('%Y-%m-%d')
                    })
        
        if tn_data:
            df_tn = pd.DataFrame(tn_data)
            
            # ã€é…è‰²ä¼˜åŒ–ã€‘ä½¿ç”¨ tableau10 é«˜å¯¹æ¯”é…è‰²
            chart = alt.Chart(df_tn).mark_line(
                point=alt.OverlayMarkDef(size=100, filled=True, color="white", strokeWidth=2)
            ).encode(
                x=alt.X(
                    'Days_Since_Start', 
                    title='ä¸Šçº¿å¤©æ•° (Days)',
                    axis=alt.Axis(values=list(final_tick_values), labelFontSize=20, titleFontSize=24, grid=True),
                    scale=alt.Scale(domain=[0, max_days_global + 1], clamp=True)
                ),
                y=alt.Y(
                    'Total_Tokens', 
                    title='Total Tokens (Billion)',
                    axis=alt.Axis(labelFontSize=20, titleFontSize=24)
                ),
                # å…³é”®ä¿®æ”¹ï¼šscale=alt.Scale(scheme='tableau10')
                color=alt.Color('Model', 
                                scale=alt.Scale(scheme='tableau10'), 
                                legend=alt.Legend(title="æ¨¡å‹åç§°", orient='bottom')),
                tooltip=['Model', 'Label', 'Total_Tokens', 'Real_Date']
            ).properties(height=500)
            
            st.altair_chart(chart, use_container_width=True)
            
            st.markdown("#### ğŸ“‹ æ•°æ®æ˜ç»†")
            df_pivot = df_tn.pivot_table(index='Model', columns='Days_Since_Start', values='Total_Tokens')
            df_pivot.columns = [f"T+{c}" for c in df_pivot.columns]
            st.dataframe(df_pivot.style.format("{:.4f} B"), use_container_width=True)
            
            data, name, mime, label = get_dataset_download(df_pivot.reset_index(), "tn_daily_comparison")
            st.download_button(label=label, data=data, file_name=name, mime=mime)

# ========================================================
# é¡µé¢ 2: å¤šæ¨¡å‹ç´¯è®¡å¢é•¿ (è¶‹åŠ¿å¯¹æ¯”)
# ========================================================
elif page == NAV_CUMULATIVE_COMPARE:
    st.subheader("å¤šæ¨¡å‹ç´¯è®¡å¢é•¿å¯¹æ¯”")
    
    selected_names = st.multiselect(
        "é€‰æ‹©è¦å¯¹æ¯”çš„æ¨¡å‹:", 
        all_model_names, 
        default=all_model_names[:3] if len(all_model_names) >=3 else all_model_names
    )

    if selected_names:
        plot_data = []
        max_day_plot = 0
        
        cols = st.columns(len(selected_names))
        for idx, name in enumerate(selected_names):
            m_df_temp = df[df['Display_Name'] == name].sort_values('Date')
            if not m_df_temp.empty:
                s_date = m_df_temp.iloc[0]['Date'].strftime('%Y-%m-%d')
                cols[idx].caption(f"ğŸ“… **{name}**: {s_date}")

        for name in selected_names:
            m_df = df[df['Display_Name'] == name].sort_values('Date')
            m_df['Cum_Tokens'] = m_df['Total_Tokens'].cumsum()
            if len(m_df) > 1: m_df = m_df.iloc[:-1]
            if m_df.empty: continue

            start_date = m_df.iloc[0]['Date']
            current_max_day = (m_df.iloc[-1]['Date'] - start_date).days
            if current_max_day > max_day_plot:
                max_day_plot = current_max_day

            for _, row in m_df.iterrows():
                day_num = (row['Date'] - start_date).days
                plot_data.append({
                    'Model': name, 'Day': day_num,
                    'Date': row['Date'].strftime('%Y-%m-%d'),
                    'Cumulative_Tokens': row['Cum_Tokens']
                })

        if plot_data:
            df_plot = pd.DataFrame(plot_data)

            # ã€é…è‰²ä¼˜åŒ–ã€‘ä½¿ç”¨ tableau10 é«˜å¯¹æ¯”é…è‰²
            base = alt.Chart(df_plot).encode(
                x=alt.X('Day', title="ä¸Šçº¿å¤©æ•° (Daily)", 
                        scale=alt.Scale(domain=[0, max_day_plot + 2], clamp=True),
                        axis=alt.Axis(labelFontSize=16, titleFontSize=18, grid=True)),
                y=alt.Y('Cumulative_Tokens', title='ç´¯è®¡ Token (Billion)', 
                        axis=alt.Axis(labelFontSize=16, titleFontSize=18)),
                # å…³é”®ä¿®æ”¹ï¼šscale=alt.Scale(scheme='tableau10')
                color=alt.Color('Model', 
                                title='æ¨¡å‹åç§°', 
                                scale=alt.Scale(scheme='tableau10'),
                                legend=alt.Legend(orient='bottom')),
                tooltip=['Model', 'Day', 'Date', 'Cumulative_Tokens']
            )
            chart = (base.mark_line(strokeWidth=3) + base.mark_circle(size=60)).properties(height=600)
            
            st.altair_chart(chart, use_container_width=True)

            st.markdown("### ğŸ“… ç´¯è®¡æ•°å€¼æ˜ç»†")
            df_pivot = df_plot.pivot_table(index='Day', columns='Model', values='Cumulative_Tokens')
            st.dataframe(df_pivot.style.format("{:.4f} B"), use_container_width=True)

            data, name, mime, label = get_dataset_download(df_pivot.reset_index(), "cumulative_growth")
            st.download_button(label=label, data=data, file_name=name, mime=mime)

# ========================================================
# é¡µé¢ 3: å•æ¨¡å‹æ¯æ—¥è¯¦æƒ… (è¶‹åŠ¿åˆ†æ + æ—¥æœŸç­›é€‰)
# ========================================================
elif page == NAV_DETAIL_DAILY:
    st.subheader("å•æ¨¡å‹æ¯æ—¥è¯¦æƒ…è¶‹åŠ¿")
    
    selected_name = st.selectbox("é€‰æ‹©æ¨¡å‹", all_model_names)
    m_df_full = df[df['Display_Name'] == selected_name].sort_values('Date')
    
    if not m_df_full.empty:
        min_date = m_df_full['Date'].min().date()
        max_date = m_df_full['Date'].max().date()
        st.success(f"ğŸ“… **{selected_name}** æ•°æ®æ”¶å½•åŒºé—´: {min_date} è‡³ {max_date}")

        col_filter1, col_filter2 = st.columns([1, 3])
        with col_filter1:
            date_range = st.date_input(
                "ğŸ” ç­›é€‰æ—¶é—´æ®µ",
                value=(min_date, max_date),
                min_value=min_date,
                max_value=max_date
            )
        
        if len(date_range) == 2:
            start_filter, end_filter = date_range
            mask = (m_df_full['Date'].dt.date >= start_filter) & (m_df_full['Date'].dt.date <= end_filter)
            m_df = m_df_full.loc[mask]
        else:
            m_df = m_df_full

        if not m_df.empty:
            latest = m_df.iloc[-1]
            c1, c2, c3 = st.columns(3)
            c1.metric("é€‰æ®µæœ€æ–°æ—¥æœŸ", latest['Date'].strftime('%Y-%m-%d'))
            c2.metric("å½“æ—¥æ¶ˆè€—", f"{latest['Total_Tokens']:.4f} B")
            if latest.get('Reasoning', 0) > 0 and latest.get('Completion', 0) > 0:
                ratio = (latest['Reasoning'] / latest['Completion']) * 100
                c3.metric("Reasoning å æ¯”", f"{ratio:.1f}%")
            else:
                c3.metric("Prompt Tokens", f"{latest['Prompt']:.4f} B")

            chart = alt.Chart(m_df).mark_line(point=True).encode(
                x=alt.X('Date', title='æ—¥æœŸ', axis=alt.Axis(format='%m-%d')),
                y=alt.Y('Total_Tokens', title='Token (Billion)'),
                tooltip=['Date', 'Total_Tokens', 'Prompt', 'Completion']
            )
            
            st.altair_chart(chart, use_container_width=True)
            
            display_cols = ['Date', 'Total_Tokens', 'Prompt', 'Completion', 'Reasoning']
            valid_cols = [c for c in display_cols if c in m_df.columns]
            st.dataframe(m_df[valid_cols].sort_values('Date', ascending=False).style.format({'Total_Tokens':'{:.4f}'}), use_container_width=True)

            data, name, mime, label = get_dataset_download(m_df[valid_cols], f"{selected_name}_daily")
            st.download_button(label=label, data=data, file_name=name, mime=mime)
        else:
            st.warning("âš ï¸ æ‰€é€‰æ—¶é—´æ®µå†…æ— æ•°æ®ã€‚")

# ========================================================
# é¡µé¢ 4: åŸå§‹æ•°æ®æ£€æŸ¥
# ========================================================
elif page == NAV_RAW_DATA:
    st.subheader("æ•°æ®åº“åŸå§‹æ•°æ®")
    
    st.markdown("#### ğŸ’¾ å…¨é‡æ•°æ®ä¸‹è½½")
    data, name, mime, label = get_dataset_download(df, "full_history_database")
    st.download_button(label=label, data=data, file_name=name, mime=mime)
    
    st.divider()
    
    check_name = st.selectbox("é€‰æ‹©è¦æ£€æŸ¥çš„æ¨¡å‹:", all_model_names)
    filtered_df = df[df['Display_Name'] == check_name].sort_values('Date', ascending=False)
    
    st.dataframe(
        filtered_df.style.format({
            'Prompt': '{:.6f} B', 'Completion': '{:.6f} B', 
            'Reasoning': '{:.6f} B', 'Total_Tokens': '{:.6f} B'
        }), use_container_width=True
    )

# ========================================================
# é¡µé¢ 5: æ¯æ—¥é€Ÿè§ˆä¸åˆ†æ
# ========================================================
elif page == NAV_DAILY_BRIEF:
    st.subheader("æ¨¡å‹è¡¨ç°é€Ÿè§ˆä¸åˆ†ææŠ¥å‘Š")
    st.caption("åŸºäºå†å²æ•°æ®çš„å¤šç»´åº¦é‡åŒ–åˆ†æï¼Œæ‰€æœ‰æŒ‡æ ‡å‡ç”±æ•°æ®è‡ªåŠ¨è®¡ç®—ç”Ÿæˆã€‚")

    # --- é¢„è®¡ç®—æ‰€æœ‰æ¨¡å‹çš„æŒ‡æ ‡ ---
    latest_date = df['Date'].max()
    two_weeks_ago = latest_date - pd.Timedelta(days=14)
    seven_days_ago = latest_date - pd.Timedelta(days=7)

    metrics_list = []
    for name in all_model_names:
        m_df = df[df['Display_Name'] == name].sort_values('Date')
        if m_df.empty:
            continue
        # å»æ‰æœ€åä¸€å¤©ï¼ˆå½“å¤©æœªç»“ç®—æ•°æ®ï¼Œå’Œå…¶ä»–é¡µé¢é€»è¾‘ä¿æŒä¸€è‡´ï¼‰
        if len(m_df) > 1:
            m_df = m_df.iloc[:-1]
        if m_df.empty:
            continue

        first_date = m_df.iloc[0]['Date']
        last_date = m_df.iloc[-1]['Date']
        days_online = max((last_date - first_date).days, 1)
        cumulative = m_df['Total_Tokens'].sum()
        daily_avg = cumulative / days_online
        peak = m_df['Total_Tokens'].max()

        # è¿‘ 7 æ—¥å¢é€Ÿ
        recent_df = m_df[m_df['Date'] >= seven_days_ago]
        recent_days = max(len(recent_df), 1)
        recent_avg = recent_df['Total_Tokens'].sum() / recent_days if not recent_df.empty else 0

        # å¢é•¿åŠ¨é‡
        momentum = (recent_avg / daily_avg) if daily_avg > 0 else 0

        metrics_list.append({
            'Model': name,
            'First_Date': first_date,
            'Last_Date': last_date,
            'Days_Online': days_online,
            'Cumulative': round(cumulative, 4),
            'Daily_Avg': round(daily_avg, 4),
            'Recent_7d_Avg': round(recent_avg, 4),
            'Momentum': round(momentum, 2),
            'Peak': round(peak, 4),
        })

    df_metrics = pd.DataFrame(metrics_list)

    if df_metrics.empty:
        st.warning("æš‚æ— å¯åˆ†æçš„æ¨¡å‹æ•°æ®ã€‚")
        st.stop()

    # è®¡ç®—ç™¾åˆ†ä½æ’åï¼ˆä¾›åç»­æ¨¡å—ä½¿ç”¨ï¼‰
    df_metrics['Pct_Rank_DailyAvg'] = df_metrics['Daily_Avg'].rank(pct=True)

    # ============================
    # æ¨¡å— A: è¿‘ä¸¤å‘¨æ–°å¢æ¨¡å‹ä¸€è§ˆ
    # ============================
    st.markdown("---")
    st.markdown("### è¿‘ä¸¤å‘¨æ–°å¢æ¨¡å‹ä¸€è§ˆ")
    st.caption(f"ç»Ÿè®¡åŒºé—´: {two_weeks_ago.strftime('%Y-%m-%d')} ~ {latest_date.strftime('%Y-%m-%d')}")

    new_models_df = df_metrics[df_metrics['First_Date'] >= two_weeks_ago].sort_values('First_Date', ascending=False)

    if new_models_df.empty:
        st.info("è¿‡å»ä¸¤å‘¨å†…æ²¡æœ‰æ–°ä¸Šçº¿çš„æ¨¡å‹ã€‚")
    else:
        st.markdown(f"è¿‡å»ä¸¤å‘¨å…±ä¸Šçº¿ **{len(new_models_df)}** ä¸ªæ–°æ¨¡å‹ã€‚")
        display_new = new_models_df[['Model', 'First_Date', 'Days_Online', 'Cumulative', 'Daily_Avg']].copy()
        display_new.columns = ['æ¨¡å‹åç§°', 'ä¸Šçº¿æ—¥æœŸ', 'ä¸Šçº¿å¤©æ•°', 'ç´¯è®¡æ¶ˆè€— (B)', 'æ—¥å‡æ¶ˆè€— (B)']
        display_new['ä¸Šçº¿æ—¥æœŸ'] = display_new['ä¸Šçº¿æ—¥æœŸ'].dt.strftime('%Y-%m-%d')
        st.dataframe(
            display_new.style.format({'ç´¯è®¡æ¶ˆè€— (B)': '{:.4f}', 'æ—¥å‡æ¶ˆè€— (B)': '{:.4f}'}),
            use_container_width=True, hide_index=True
        )

    # ============================
    # æ¨¡å— B (åŸ D): æ–°æ¨¡å‹ç´¯è®¡å¢é•¿å¯¹æ¯”
    # ============================
    if not new_models_df.empty:
        st.markdown("---")
        st.markdown("### æ–°æ¨¡å‹ç´¯è®¡å¢é•¿å¯¹æ¯”")

        new_model_names = new_models_df['Model'].tolist()
        plot_new = []
        max_day_new = 0

        for name in new_model_names:
            m_df = df[df['Display_Name'] == name].sort_values('Date')
            m_df['Cum_Tokens'] = m_df['Total_Tokens'].cumsum()
            if len(m_df) > 1:
                m_df = m_df.iloc[:-1]
            if m_df.empty:
                continue
            start_date = m_df.iloc[0]['Date']
            current_max = (m_df.iloc[-1]['Date'] - start_date).days
            if current_max > max_day_new:
                max_day_new = current_max
            for _, row in m_df.iterrows():
                day_n = (row['Date'] - start_date).days
                plot_new.append({
                    'Model': name, 'Day': day_n,
                    'Date': row['Date'].strftime('%Y-%m-%d'),
                    'Cumulative_Tokens': row['Cum_Tokens']
                })

        if plot_new:
            df_plot_new = pd.DataFrame(plot_new)
            base_new = alt.Chart(df_plot_new).encode(
                x=alt.X('Day', title='ä¸Šçº¿å¤©æ•°',
                        scale=alt.Scale(domain=[0, max_day_new + 2], clamp=True),
                        # å¼ºåˆ¶ tickMinStep=1 é¿å…æ˜¾ç¤ºå°æ•°åˆ»åº¦
                        axis=alt.Axis(tickMinStep=1, format='d', labelFontSize=14, titleFontSize=16, grid=True)),
                y=alt.Y('Cumulative_Tokens', title='ç´¯è®¡ Token (Billion)',
                        axis=alt.Axis(labelFontSize=14, titleFontSize=16)),
                color=alt.Color('Model', title='æ¨¡å‹',
                                scale=alt.Scale(scheme='tableau10'),
                                legend=alt.Legend(orient='bottom')),
                tooltip=['Model', 'Day', 'Date', 'Cumulative_Tokens']
            )
            chart_new = (base_new.mark_line(strokeWidth=3) + base_new.mark_circle(size=60)).properties(height=500)
            st.altair_chart(chart_new, use_container_width=True)
        else:
            st.info("æ–°æ¨¡å‹æš‚æ— è¶³å¤Ÿæ•°æ®ç»˜åˆ¶è¶‹åŠ¿å›¾ã€‚")

    # ============================
    # æ¨¡å— C: åˆ†ææ‘˜è¦ (è¡¨æ ¼åŒ–)
    # ============================
    st.markdown("---")
    st.markdown("### ç»¼åˆåˆ†ææ‘˜è¦")
    st.caption(f"åˆ†æåŸºå‡†æ—¥: {latest_date.strftime('%Y-%m-%d')}")

    # Top 3 ç´¯è®¡æ¶ˆè€—
    with st.expander("ç´¯è®¡æ¶ˆè€— Top 3", expanded=True):
        top3_cum = df_metrics.nlargest(3, 'Cumulative').copy()
        top3_cum['Rank'] = range(1, len(top3_cum) + 1)
        display_top3 = top3_cum[['Rank', 'Model', 'Cumulative', 'Days_Online', 'Daily_Avg']].copy()
        display_top3.columns = ['æ’å', 'æ¨¡å‹', 'ç´¯è®¡æ¶ˆè€— (B)', 'ä¸Šçº¿å¤©æ•°', 'æ—¥å‡æ¶ˆè€— (B)']
        st.dataframe(
            display_top3.style.format({'ç´¯è®¡æ¶ˆè€— (B)': '{:.4f}', 'æ—¥å‡æ¶ˆè€— (B)': '{:.4f}'}),
            use_container_width=True, hide_index=True
        )

    # è¿‘ 7 æ—¥å¢é€Ÿæœ€å¿«
    with st.expander("è¿‘7æ—¥å¢é€Ÿé¢†å…ˆ (Top 3)", expanded=True):
        top3_recent = df_metrics.nlargest(3, 'Recent_7d_Avg').copy()
        top3_recent['Rank'] = range(1, len(top3_recent) + 1)
        display_recent = top3_recent[['Rank', 'Model', 'Recent_7d_Avg']].copy()
        display_recent.columns = ['æ’å', 'æ¨¡å‹', 'è¿‘7æ—¥æ—¥å‡æ¶ˆè€— (B)']
        st.dataframe(
            display_recent.style.format({'è¿‘7æ—¥æ—¥å‡æ¶ˆè€— (B)': '{:.4f}'}),
            use_container_width=True, hide_index=True
        )

    # åŠ é€Ÿå¢é•¿ä¸­çš„æ¨¡å‹
    with st.expander("æ­£åœ¨åŠ é€Ÿå¢é•¿ (åŠ¨é‡ > 1.2)", expanded=True):
        accel = df_metrics[df_metrics['Momentum'] >= 1.2].sort_values('Momentum', ascending=False)
        if not accel.empty:
            accel['Growth_Pct'] = (accel['Momentum'] - 1) * 100
            display_accel = accel[['Model', 'Momentum', 'Growth_Pct']].head(5).copy()
            display_accel.columns = ['æ¨¡å‹', 'åŠ¨é‡å€¼', 'è¿‘æœŸå¢é€Ÿè¶…å‡ºå‡å€¼ (%)']
            st.dataframe(
                display_accel.style.format({'åŠ¨é‡å€¼': '{:.2f}', 'è¿‘æœŸå¢é€Ÿè¶…å‡ºå‡å€¼ (%)': '+{:.0f}%'}),
                use_container_width=True, hide_index=True
            )
        else:
            st.info("æš‚æ— æ˜æ˜¾åŠ é€Ÿå¢é•¿çš„æ¨¡å‹ã€‚")

    # å¢é€Ÿæ”¾ç¼“çš„æ¨¡å‹
    with st.expander("å¢é€Ÿæ”¾ç¼“å…³æ³¨ (åŠ¨é‡ < 0.8)", expanded=True):
        decel = df_metrics[(df_metrics['Momentum'] <= 0.8) & (df_metrics['Days_Online'] >= 7)].sort_values('Momentum')
        if not decel.empty:
            decel['Slowdown_Pct'] = (1 - decel['Momentum']) * 100
            display_decel = decel[['Model', 'Momentum', 'Slowdown_Pct']].head(5).copy()
            display_decel.columns = ['æ¨¡å‹', 'åŠ¨é‡å€¼', 'è¿‘æœŸå¢é€Ÿä½äºå‡å€¼ (%)']
            st.dataframe(
                display_decel.style.format({'åŠ¨é‡å€¼': '{:.2f}', 'è¿‘æœŸå¢é€Ÿä½äºå‡å€¼ (%)': '-{:.0f}%'}),
                use_container_width=True, hide_index=True
            )
        else:
            st.info("æš‚æ— æ˜æ˜¾å¢é€Ÿæ”¾ç¼“çš„æ¨¡å‹ã€‚")

    # æ–°æ¨¡å‹é€Ÿè¯„ï¼ˆä½¿ç”¨ç™¾åˆ†ä½æ’åäº”çº§åˆ¶ï¼‰
    if not new_models_df.empty:
        with st.expander("æ–°æ¨¡å‹åˆæœŸè¡¨ç°è¯„çº§", expanded=True):
            rating_data = []
            for row in new_models_df.itertuples():
                pct_rank = row.Pct_Rank_DailyAvg
                if pct_rank >= 0.90:
                    tier, desc = "S Â· å¤´éƒ¨æ°´å¹³", f"è¶…è¿‡ {pct_rank*100:.0f}% æ¨¡å‹"
                elif pct_rank >= 0.75:
                    tier, desc = "A Â· è¡¨ç°ä¼˜å¼‚", f"è¶…è¿‡ {pct_rank*100:.0f}% æ¨¡å‹"
                elif pct_rank >= 0.50:
                    tier, desc = "B Â· ä¸­ç­‰æ°´å¹³", "æ—¥å‡ > ä¸­ä½æ•°"
                elif pct_rank >= 0.25:
                    tier, desc = "C Â· ä½äºé¢„æœŸ", f"ä»…è¶… {pct_rank*100:.0f}% æ¨¡å‹"
                else:
                    tier, desc = "D Â· èµ·æ­¥ç¼“æ…¢", f"å {(1-pct_rank)*100:.0f}% åˆ†ä½"
                
                rating_data.append({
                    'æ¨¡å‹': row.Model,
                    'ä¸Šçº¿æ—¥æœŸ': row.First_Date.strftime('%m-%d'),
                    'æ—¥å‡æ¶ˆè€— (B)': row.Daily_Avg,
                    'è¯„çº§': tier,
                    'è¯´æ˜': desc
                })
            
            df_rating = pd.DataFrame(rating_data)
            st.dataframe(
                df_rating.style.format({'æ—¥å‡æ¶ˆè€— (B)': '{:.4f}'}),
                use_container_width=True, hide_index=True
            )

    # ============================
    # æ¨¡å— D (åŸ B): å…¨æ¨¡å‹è¡¨ç°æ’å (ç§»è‡³æœ€å)
    # ============================
    st.markdown("---")
    st.markdown("### å…¨æ¨¡å‹è¡¨ç°æ’å (Top 15)")

    RANK_OPTIONS = {
        'ç´¯è®¡æ€»é‡': 'Cumulative',
        'æ—¥å‡æ¶ˆè€—': 'Daily_Avg',
        'è¿‘7æ—¥å¢é€Ÿ': 'Recent_7d_Avg',
        'å¢é•¿åŠ¨é‡': 'Momentum',
        'å³°å€¼æ¶ˆè€—': 'Peak',
        'ä¸Šçº¿å¤©æ•°': 'Days_Online'
    }
    col_rank1, col_rank2 = st.columns([1, 3])
    with col_rank1:
        rank_label = st.selectbox("é€‰æ‹©æ’åç»´åº¦", list(RANK_OPTIONS.keys()))
    rank_col = RANK_OPTIONS[rank_label]

    df_ranked = df_metrics.sort_values(rank_col, ascending=False).head(15).reset_index(drop=True)
    df_ranked.index = df_ranked.index + 1

    chart_rank = alt.Chart(df_ranked).mark_bar(
        cornerRadiusTopLeft=4, cornerRadiusTopRight=4
    ).encode(
        x=alt.X('Model', sort='-y', title='æ¨¡å‹',
                axis=alt.Axis(labelAngle=-45, labelFontSize=11)),
        y=alt.Y(rank_col, title=rank_label,
                axis=alt.Axis(labelFontSize=14, titleFontSize=16)),
        color=alt.Color('Model', legend=None, scale=alt.Scale(scheme='tableau10')),
        tooltip=['Model', alt.Tooltip(rank_col, title=rank_label, format='.4f')]
    ).properties(height=400)
    st.altair_chart(chart_rank, use_container_width=True)

    display_ranked = df_ranked[['Model', 'Days_Online', 'Cumulative', 'Daily_Avg', 'Recent_7d_Avg', 'Momentum', 'Peak']].copy()
    display_ranked.columns = ['æ¨¡å‹', 'ä¸Šçº¿å¤©æ•°', 'ç´¯è®¡ (B)', 'æ—¥å‡ (B)', 'è¿‘7æ—¥å‡ (B)', 'åŠ¨é‡', 'å³°å€¼ (B)']

    def highlight_momentum(val):
        if isinstance(val, (int, float)):
            if val >= 1.2:
                return 'background-color: #d4edda; color: #155724'
            elif val <= 0.8:
                return 'background-color: #f8d7da; color: #721c24'
        return ''

    st.dataframe(
        display_ranked.style
            .format({'ç´¯è®¡ (B)': '{:.4f}', 'æ—¥å‡ (B)': '{:.4f}', 'è¿‘7æ—¥å‡ (B)': '{:.4f}', 'åŠ¨é‡': '{:.2f}', 'å³°å€¼ (B)': '{:.4f}'})
            .map(highlight_momentum, subset=['åŠ¨é‡']),
        use_container_width=True, hide_index=False
    )
    st.caption("åŠ¨é‡ > 1.2 (ç»¿è‰²èƒŒæ™¯) = åŠ é€Ÿå¢é•¿ Â· åŠ¨é‡ < 0.8 (çº¢è‰²èƒŒæ™¯) = å¢é€Ÿæ”¾ç¼“")

    # ============================
    # æ¨¡å— E: è¿‘ä¸¤å‘¨æ–°æ¨¡å‹åŠ¨æ€ (RSS)
    # ============================
    st.markdown("---")
    st.markdown("### è¿‘ä¸¤å‘¨æ–°æ¨¡å‹åŠ¨æ€")

    if new_models_df.empty:
        st.info("è¿‘ä¸¤å‘¨å†…æ— æ–°ä¸Šçº¿æ¨¡å‹ï¼Œæš‚æ— ç›¸å…³æ–°é—»å¯æ£€ç´¢ã€‚")
    else:
        import re as _re
        import requests as _requests


        # â”€â”€ AI ä¸“ä¸šåª’ä½“ RSS æº â”€â”€
        RSS_FEEDS = [
            ("Reddit LocalLLaMA", "https://www.reddit.com/r/LocalLLaMA/new/.rss"),
            ("Simon Willison",    "https://simonwillison.net/atom/entries/"),
            ("TechCrunch AI",     "https://techcrunch.com/category/artificial-intelligence/feed/"),
            ("The Verge AI",      "https://www.theverge.com/rss/ai-artificial-intelligence/index.xml"),
            ("Ars Technica",      "https://feeds.arstechnica.com/arstechnica/technology-lab"),
            ("Wired AI",          "https://www.wired.com/feed/tag/ai/latest/rss"),
            ("MIT Tech Review",   "https://www.technologyreview.com/feed/"),
            ("InfoQ AI",          "https://feed.infoq.com/"),
            ("OpenAI Blog",       "https://openai.com/blog/rss.xml"),
            ("Hugging Face Blog", "https://huggingface.co/blog/feed.xml"),
            ("Google DeepMind",   "https://deepmind.google/blog/rss.xml"),
            ("Last Week in AI",   "https://lastweekin.ai/feed"),
        ]


        # â”€â”€ ä»æ¨¡å‹å…¨åæå–å“ç‰Œå â”€â”€
        def extract_brand(full_name):
            base = full_name.split('/')[-1]
            return base.split('-')[0].lower()

        # â”€â”€ è‡ªåŠ¨æ‰“æ ‡ç­¾ï¼šè¿”å›åŒ¹é…çš„å“ç‰Œåï¼Œæ— åŒ¹é…è¿”å› None â”€â”€
        def detect_tag(text, brand_label_map):
            text_lower = text.lower()
            for brand, label in brand_label_map.items():
                if brand in text_lower:
                    return label
            return None

        # â”€â”€ æ„å»ºå“ç‰Œåæ ‡ç­¾æ˜ å°„ â”€â”€
        model_names_raw = new_models_df['Model'].tolist()
        brand_label_map = {}
        
        # å¼ºåˆ¶ç½®é¡¶ OpenRouterï¼ˆç¡®ä¿ä¼˜å…ˆåŒ¹é…ï¼‰
        brand_label_map["openrouter"] = "openrouter"
        brand_label_map["open router"] = "openrouter" 
        
        for full_name in model_names_raw:
            brand = extract_brand(full_name)
            if brand and len(brand) >= 3:
                brand_label_map[brand] = brand
        
        # è¡¥å……å‚å•†åˆ«åå’Œå…³è”ï¼ˆå›½å¤–+å›½å†…ä¸»æµæ¨¡å‹ï¼‰
        ALIAS_MAP = {
            # å›½å¤–
            "gpt": "openai", "o1": "openai", "o3": "openai", 
            "claude": "anthropic", "gemini": "google", 
            "llama": "meta", "mistral": "mistralai",
            # å›½å†…
            "kimi": "moonshot", "yi": "01.ai", 
            "doubao": "bytedance", "hunyuan": "tencent",
            "ernie": "baidu", "qwen": "alibaba",
            "chatglm": "zhipu", "glm": "zhipu",
            "minimax": "minimax", "step": "stepfun",
            "deepseek": "deepseek", "baichuan": "baichuan",
            "sensechat": "sensetime", "spark": "iflytek"
        }
        for short, full in ALIAS_MAP.items():
            # åªè¦æ–°æ¨¡å‹é‡Œå‡ºç°äº† short (å¦‚ claude)ï¼Œå°±åŒæ—¶ä¹Ÿå…³æ³¨ full (anthropic)
            if short in brand_label_map:
                brand_label_map[full] = full


        cutoff = latest_date - pd.Timedelta(days=14)
        cutoff_str = cutoff.strftime('%Y-%m-%d')

        # â”€â”€ ç¿»è¯‘å‡½æ•°ï¼ˆç¼“å­˜ 24 å°æ—¶ï¼‰â”€â”€
        @st.cache_data(ttl=86400)
        def translate_zh(text):
            if not text or not text.strip():
                return text
            try:
                from deep_translator import GoogleTranslator
                return GoogleTranslator(source='en', target='zh-CN').translate(text[:500])
            except Exception:
                return text

        # â”€â”€ æŠ“å–å¹¶è§£æ RSSï¼ˆç¼“å­˜ 3 å°æ—¶ï¼Œå¸¦ User-Agent é˜²åçˆ¬ï¼‰â”€â”€
        @st.cache_data(ttl=10800)
        def fetch_rss_articles(cutoff_str):
            import feedparser
            cutoff_dt = pd.Timestamp(cutoff_str, tz='UTC')
            results = []
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
            
            for feed_name, feed_url in RSS_FEEDS:
                try:
                    # å…ˆç”¨ requests è·å–å†…å®¹ï¼ˆç»•è¿‡ Reddit ç­‰ç«™ç‚¹çš„ UA æ£€æŸ¥ï¼‰
                    resp = _requests.get(feed_url, headers=headers, timeout=10)
                    if resp.status_code != 200:
                        continue
                        
                    feed = feedparser.parse(resp.content)
                    
                    for entry in feed.entries:
                        title = entry.get('title', '').strip()
                        link  = entry.get('link', '#')
                        
                        # æ‘˜è¦ï¼šä¼˜å…ˆ summaryï¼Œå…¶æ¬¡ content
                        desc_raw = entry.get('summary', '') or ''
                        if not desc_raw and entry.get('content'):
                            desc_raw = entry['content'][0].get('value', '')
                        import re as _re2
                        desc = _re2.sub(r'<[^>]+>', '', desc_raw).strip()[:300]
                        
                        # å‘å¸ƒæ—¶é—´
                        pub_parsed = entry.get('published_parsed') or entry.get('updated_parsed')
                        if pub_parsed:
                            pub_dt = pd.Timestamp(*pub_parsed[:6], tz='UTC')
                        else:
                            pub_dt = pd.Timestamp.now(tz='UTC')
                            
                        if pub_dt < cutoff_dt:
                            continue
                            
                        results.append({
                            'title': title, 'desc': desc, 'link': link,
                            'source': feed_name, 'date': pub_dt.strftime('%Y-%m-%d'),
                        })
                except Exception:
                    continue
            
            results.sort(key=lambda x: x['date'], reverse=True)
            return results


        # æ˜¾ç¤ºåŒ¹é…çš„å“ç‰Œï¼ˆOpenRouter ç½®é¡¶æ˜¾ç¤ºï¼‰
        display_brands = list(brand_label_map.keys())
        if "openrouter" in display_brands:
            display_brands.remove("openrouter")
            display_brands.insert(0, "openrouter")
        brand_display = ', '.join(display_brands[:10])
        
        st.caption(f"æ•°æ®æ¥æº: Reddit / Simon Willison / TechCrunch / The Verge ç­‰ Â· æ¯3å°æ—¶æ›´æ–° Â· é‡ç‚¹å…³æ³¨: {brand_display}")

        all_articles = fetch_rss_articles(cutoff_str)

        # â”€â”€ è¿‡æ»¤å‡ºä¸æ–°æ¨¡å‹ç›¸å…³çš„æ–‡ç«  â”€â”€
        matched = []
        for art in all_articles:
            # æœç´¢åŒ¹é…
            tag = detect_tag(f"{art['title']} {art['desc']}", brand_label_map)
            if tag is not None:
                art['tag'] = tag
                matched.append(art)

        if not matched:
            st.info("è¿‘ä¸¤å‘¨å†… AI åª’ä½“ä¸­æœªæ‰¾åˆ°è¿™äº›æ¨¡å‹çš„ç›¸å…³æŠ¥é“ã€‚")
        else:
            st.markdown(f"å…±æ‰¾åˆ° **{len(matched)}** æ¡ç›¸å…³æŠ¥é“ï¼ˆæ ‡é¢˜å’Œæ‘˜è¦å·²ç¿»è¯‘ä¸ºä¸­æ–‡ï¼‰")
            for art in matched:
                title_zh = translate_zh(art['title']) if art['title'] else "æ— æ ‡é¢˜"
                desc_zh = translate_zh(art['desc']) if art['desc'] else ""
                
                # æ ‡é¢˜åŠ ä¸Šæ ‡ç­¾ï¼Œå¦‚æœæ˜¯ OpenRouter åˆ™é«˜äº®
                tag_str = f"[{art['tag']}]"
                if art['tag'] == "openrouter":
                    tag_str = "ğŸ”¥ [OpenRouter]"
                
                with st.expander(
                    f"{tag_str}  {title_zh}  Â·  {art['source']}  Â·  {art['date']}",
                    expanded=False
                ):
                    if desc_zh:
                        st.markdown(desc_zh)
                    st.caption(f"åŸæ–‡: {art['title']}")
                    st.markdown(f"[é˜…è¯»åŸæ–‡ â†’]({art['link']})")



    # ============================
    # æ¨¡å— F: æŒ‡æ ‡å®šä¹‰ä¸å…¬å¼è¯´æ˜
    # ============================
    st.markdown("---")
    st.markdown("### é™„å½•: æŒ‡æ ‡å®šä¹‰ä¸è®¡ç®—å…¬å¼")
    with st.expander("æŸ¥çœ‹å®Œæ•´æŒ‡æ ‡è¯´æ˜", expanded=False):
        st.markdown("""
| æŒ‡æ ‡ | å®šä¹‰ | è®¡ç®—å…¬å¼ |
|------|------|----------|
| **æ—¥å‡æ¶ˆè€—** | æ¨¡å‹å…¨ç”Ÿå‘½å‘¨æœŸå†…å¹³å‡æ¯å¤©çš„ Token æ¶ˆè€—é‡ | `ç´¯è®¡æ€»é‡ Ã· ä¸Šçº¿å¤©æ•°` |
| **è¿‘7æ—¥å¢é€Ÿ** | æœ€è¿‘ 7 ä¸ªè‡ªç„¶æ—¥å†…çš„æ—¥å¹³å‡ Token æ¶ˆè€—é‡ | `Î£(è¿‘7æ—¥ Total_Tokens) Ã· è¿‘7æ—¥æ•°æ®æ¡æ•°` |
| **å¢é•¿åŠ¨é‡** | è¿‘æœŸæ´»è·ƒåº¦ç›¸å¯¹äºå…¨ç”Ÿå‘½å‘¨æœŸå‡å€¼çš„æ¯”ç‡ | `è¿‘7æ—¥å¢é€Ÿ Ã· æ—¥å‡æ¶ˆè€—` |
| **å³°å€¼æ¶ˆè€—** | å†å²å•æ—¥æœ€é«˜ Token æ¶ˆè€—é‡ | `max(æ¯æ—¥ Total_Tokens)` |
| **ç´¯è®¡æ€»é‡** | æ¨¡å‹ä¸Šçº¿ä»¥æ¥æ‰€æœ‰æ—¥æœŸ Token æ¶ˆè€—ä¹‹å’Œ | `Î£(Total_Tokens)` |
| **ä¸Šçº¿å¤©æ•°** | æ¨¡å‹é¦–æ¬¡å‡ºç°åœ¨æ•°æ®åº“åˆ°æœ€æ–°æ•°æ®çš„å¤©æ•° | `æœ€æ–°æ•°æ®æ—¥æœŸ - é¦–æ¬¡å‡ºç°æ—¥æœŸ` |

**åŠ¨é‡è§£è¯»:**
- åŠ¨é‡ = 1.0 â†’ è¿‘æœŸå¢é€Ÿä¸å…¨æœŸå‡å€¼æŒå¹³
- åŠ¨é‡ > 1.2 â†’ è¿‘æœŸå¤„äºåŠ é€Ÿå¢é•¿é˜¶æ®µ
- åŠ¨é‡ < 0.8 â†’ è¿‘æœŸå¢é€Ÿæ”¾ç¼“ï¼Œå¯èƒ½è¿›å…¥è¡°é€€æœŸ

**æ–°æ¨¡å‹è¯„çº§è¯´æ˜:**

è¯„çº§é‡‡ç”¨**ç™¾åˆ†ä½æ’åæ³• (Percentile Rank)**ï¼Œå°†æ–°æ¨¡å‹çš„æ—¥å‡æ¶ˆè€—æ”¾å…¥å…¨éƒ¨æ¨¡å‹çš„æ—¥å‡æ¶ˆè€—åˆ†å¸ƒä¸­è®¡ç®—æ’åç™¾åˆ†ä½:
- `ç™¾åˆ†ä½ = æ—¥å‡æ¶ˆè€— < è¯¥æ¨¡å‹çš„æ¨¡å‹æ•°é‡ Ã· æ€»æ¨¡å‹æ•°`

| è¯„çº§ | ç™¾åˆ†ä½åŒºé—´ | å«ä¹‰ |
|------|-----------|------|
| **S Â· å¤´éƒ¨æ°´å¹³** | â‰¥ P90 | æ—¥å‡æ¶ˆè€—è¶…è¿‡ 90% çš„æ¨¡å‹ï¼Œå±äºé¡¶çº§è¡¨ç° |
| **A Â· è¡¨ç°ä¼˜å¼‚** | P75 ~ P90 | æ—¥å‡æ¶ˆè€—å¤„äºå‰ 25%ï¼Œå¢é•¿åŠ¿å¤´å¼ºåŠ² |
| **B Â· ä¸­ç­‰æ°´å¹³** | P50 ~ P75 | æ—¥å‡æ¶ˆè€—é«˜äºä¸­ä½æ•°ï¼Œè¡¨ç°ä¸­è§„ä¸­çŸ© |
| **C Â· ä½äºé¢„æœŸ** | P25 ~ P50 | æ—¥å‡æ¶ˆè€—å¤„äºä¸­ä½æ•°ä»¥ä¸‹ï¼Œå…³æ³¨åç»­èµ°åŠ¿ |
| **D Â· èµ·æ­¥ç¼“æ…¢** | < P25     | æ—¥å‡æ¶ˆè€—å¤„äºå€’æ•° 25%ï¼Œå¸‚åœºæ¥å—åº¦è¾ƒä½ |
""")

# ========================================================
# é¡µé¢ 6: ä¾›åº”å•†ä»·æ ¼ä¸æœ‰æ•ˆå®šä»·åˆ†æ
# ========================================================
elif page == NAV_PRICING:
    st.subheader("æ¨¡å‹å®šä»·")
    st.caption("åŸºäº OpenRouter å‰ç«¯ API æŠ“å–çš„æœ€æ–°å®é™…æœ‰æ•ˆä»·æ ¼ã€‚")
    
    if df_price is None or df_price.empty:
        st.warning("æš‚æœªå‘ç°å¯ç”¨çš„å®šä»·æ•°æ®ã€‚")
    else:
        all_models = sorted(df_price['Model'].unique())
        selected_price_model = st.selectbox("é€‰æ‹©æ¨¡å‹:", all_models, index=0)

        # è·å–è¯¥æ¨¡å‹æ‰€æœ‰å†å²æ—¶é—´ç‚¹çš„æ•°æ®
        m_price_df = df_price[df_price['Model'] == selected_price_model].copy()
        
        # å°†æœ€æ–°çš„ç»¼åˆæŠ¥ä»·æ‹†å‡ºæ¥å±•ç¤º KPI
        latest_pricing_date = m_price_df['Date'].max()
        df_latest_prices = m_price_df[m_price_df['Date'] == latest_pricing_date]
        
        weighted_avg = df_latest_prices[df_latest_prices['Provider'] == 'Weighted Average']
        provider_latest = df_latest_prices[df_latest_prices['Provider'] != 'Weighted Average'].sort_values('Input_Price_1M')
        
        if not weighted_avg.empty:
            wa_row = weighted_avg.iloc[0]
            st.markdown("### æœ€æ–°æœ‰æ•ˆä»·æ ¼ (Weighted Average)")
            col1, col2 = st.columns(2)
            col1.metric("Input Price ($/1M)", f"${wa_row['Input_Price_1M']:.4f}")
            col2.metric("Output Price ($/1M)", f"${wa_row['Output_Price_1M']:.4f}")
        
        st.markdown("---")
        
        # === å›¾1: æœ‰æ•ˆä»·æ ¼è¶‹åŠ¿ (Weighted Average çš„ Input+Output å†å²) ===
        st.markdown("### æœ‰æ•ˆä»·æ ¼è¶‹åŠ¿")
        wa_history = m_price_df[m_price_df['Provider'] == 'Weighted Average'].copy()
        if not wa_history.empty:
            wa_history['Date'] = pd.to_datetime(wa_history['Date'])
            wa_long = wa_history.melt(
                id_vars=['Date'],
                value_vars=['Input_Price_1M', 'Output_Price_1M'],
                var_name='Type', value_name='Price'
            ).dropna(subset=['Price'])
            wa_long['Type'] = wa_long['Type'].map({'Input_Price_1M': 'Input', 'Output_Price_1M': 'Output'})
            
            chart_wa = alt.Chart(wa_long).mark_line(point=True).encode(
                x=alt.X('Date:T', title='æ—¶é—´', axis=alt.Axis(format='%m/%d')),
                y=alt.Y('Price:Q', title='ä»·æ ¼ ($/1M Tokens)'),
                color=alt.Color('Type:N', title='ç±»å‹'),
                tooltip=['Date:T', 'Type', alt.Tooltip('Price:Q', format='$.4f')]
            ).properties(height=300)
            st.altair_chart(chart_wa, use_container_width=True)
        else:
            st.info("æš‚æ— æœ‰æ•ˆä»·æ ¼å†å²æ•°æ®ã€‚")
        
        st.markdown("---")
        
        # === å›¾2: å„ä¾›åº”å•† Input ä»·æ ¼è¶‹åŠ¿æŠ˜çº¿å›¾ ===
        st.markdown("### å„ä¾›åº”å•† Input ä»·æ ¼è¶‹åŠ¿")
        provider_history = m_price_df[m_price_df['Provider'] != 'Weighted Average'].copy()
        if not provider_history.empty:
            provider_history['Date'] = pd.to_datetime(provider_history['Date'])
            
            chart_input = alt.Chart(provider_history).mark_line(point=True).encode(
                x=alt.X('Date:T', title='æ—¶é—´', axis=alt.Axis(format='%m/%d')),
                y=alt.Y('Input_Price_1M:Q', title='Input ä»·æ ¼ ($/1M Tokens)'),
                color=alt.Color('Provider:N', title='ä¾›åº”å•†', scale=alt.Scale(scheme='tableau20')),
                tooltip=['Date:T', 'Provider', alt.Tooltip('Input_Price_1M:Q', format='$.4f')]
            ).properties(height=350)
            st.altair_chart(chart_input, use_container_width=True)
        else:
            st.info("æš‚æ— ä¾›åº”å•† Input ä»·æ ¼æ•°æ®ã€‚")
        
        st.markdown("---")
        
        # === å›¾3: å„ä¾›åº”å•† Output ä»·æ ¼è¶‹åŠ¿æŠ˜çº¿å›¾ ===
        st.markdown("### å„ä¾›åº”å•† Output ä»·æ ¼è¶‹åŠ¿")
        if not provider_history.empty:
            chart_output = alt.Chart(provider_history).mark_line(point=True).encode(
                x=alt.X('Date:T', title='æ—¶é—´', axis=alt.Axis(format='%m/%d')),
                y=alt.Y('Output_Price_1M:Q', title='Output ä»·æ ¼ ($/1M Tokens)'),
                color=alt.Color('Provider:N', title='ä¾›åº”å•†', scale=alt.Scale(scheme='tableau20')),
                tooltip=['Date:T', 'Provider', alt.Tooltip('Output_Price_1M:Q', format='$.4f')]
            ).properties(height=350)
            st.altair_chart(chart_output, use_container_width=True)
        else:
            st.info("æš‚æ— ä¾›åº”å•† Output ä»·æ ¼æ•°æ®ã€‚")
        
        st.markdown("---")
        
        # ä¾›åº”å•†è¯¦æƒ…è¡¨æ ¼ï¼ˆæœ€æ–°ä¸€å¤©ï¼‰
        st.markdown("### ä¾›åº”å•†è¯¦æƒ… (æœ€æ–°)")
        if not provider_latest.empty:
            st.dataframe(
                provider_latest[['Provider', 'Input_Price_1M', 'Output_Price_1M', 'Cache_Hit_Rate']].style.format({
                    'Input_Price_1M': '${:.4f}',
                    'Output_Price_1M': '${:.4f}',
                    'Cache_Hit_Rate': '{:.1%}'
                }),
                use_container_width=True,
                hide_index=True
            )
            
        data, name, mime, label = get_dataset_download(df_price, "openrouter_pricing_full")
        st.download_button(label=label, data=data, file_name=name, mime=mime)

# ========================================================
# é¡µé¢ 7: Benchmark è·‘åˆ†æ•°æ®çŸ©é˜µ
# ========================================================
elif page == NAV_BENCHMARK:
    st.subheader("åŸºå‡†æµ‹è¯•ä¸æ’è¡Œæ¦œ")
    st.caption("æ•°æ®æºï¼šArtificial Analysis åŸºå‡†è·‘åˆ† + LMARENA (Chatbot Arena) ç«æŠ€æ’åã€‚")
    
    tab1, tab2, tab3 = st.tabs([
        "å•æŒ‡æ ‡æ’è¡Œ (AA Benchmark)",
        "å¤šæŒ‡æ ‡çŸ©é˜µ (AA Benchmark)",
        "LMARENA ç«æŠ€æ’å"
    ])
    
    # --- Tab 1 & 2: åŸæœ‰ Artificial Analysis Benchmark ---
    if df_bench is None or df_bench.empty:
        with tab1:
            st.warning("æš‚æœªå‘ç°å¯ç”¨çš„ Benchmark æ•°æ®ï¼Œè¯·ç¡®è®¤æ˜¯å¦æˆåŠŸè¿è¡Œ `openrouter_benchmark_scraper.py`ã€‚")
        with tab2:
            st.warning("æš‚æœªå‘ç°å¯ç”¨çš„ Benchmark æ•°æ®ã€‚")
    else:
        latest_bench_date = df_bench['Date'].max()
        df_latest_bench = df_bench[df_bench['Date'] == latest_bench_date].drop(columns=['Date'])
        
        # çŸ©é˜µè½¬ç½®ï¼šè®© Model å˜æˆ indexï¼ŒMetrics å˜æˆ columns
        bench_melted = df_latest_bench.melt(id_vars=['Metric'], var_name='Model', value_name='Score')
        bench_pivot = bench_melted.pivot_table(index='Model', columns='Metric', values='Score')
        
        metrics_available = bench_pivot.columns.tolist()
        
        with tab1:
            st.markdown("### æ ¸å¿ƒåŸºå‡†æµ‹è¯•æ’è¡Œæ¦œ")
            st.info(f"æ•°æ®æ›´æ–°äº: **{latest_bench_date.strftime('%Y-%m-%d')}**")
            primary_metric = st.selectbox("é€‰æ‹©æ’åºæŒ‡æ ‡:", metrics_available, index=0, key="tab1_metric")
            
            if primary_metric:
                bench_sorted = bench_pivot.sort_values(by=primary_metric, ascending=False).reset_index()
                bench_sorted = bench_sorted.dropna(subset=[primary_metric])
                
                top_10_models = bench_sorted['Model'].head(10).tolist()
                
                selected_b_models = st.multiselect(
                    "é€‰æ‹©å¯¹æ¯”æ¨¡å‹ (é»˜è®¤å‰10):", 
                    bench_sorted['Model'].tolist(), 
                    default=top_10_models,
                    key="tab1_models"
                )
                
                if selected_b_models:
                    plot_df = bench_sorted[bench_sorted['Model'].isin(selected_b_models)]
                    
                    chart_vertical = alt.Chart(plot_df).mark_bar(
                        cornerRadiusTopLeft=3, cornerRadiusTopRight=3
                    ).encode(
                        x=alt.X('Model:N', sort='-y', title='æ¨¡å‹åç§°', axis=alt.Axis(labelAngle=-45, labelOverlap=False)),
                        y=alt.Y(f'{primary_metric}:Q', title='å¾—åˆ†æ•°å€¼'),
                        color=alt.Color('Model:N', legend=None, scale=alt.Scale(scheme='tableau20')),
                        tooltip=['Model', alt.Tooltip(f'{primary_metric}:Q', format='.3f')]
                    ).properties(height=500)
                    
                    st.altair_chart(chart_vertical, use_container_width=True)
                else:
                    st.info("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”ç»˜åˆ¶ã€‚")
                    
        with tab2:
            st.markdown("### å¤šç»´åº¦æŒ‡æ ‡äº¤å‰å¯¹æ¯”")
            st.info(f"æ•°æ®æ›´æ–°äº: **{latest_bench_date.strftime('%Y-%m-%d')}**")
            col_t1, col_t2 = st.columns([1, 2])
            with col_t1:
                t2_metric = st.selectbox("æ’åºæŒ‡æ ‡ä¼˜å…ˆæƒ:", metrics_available, index=0, key="tab2_main_metric")
            with col_t2:
                t2_metrics = st.multiselect("éœ€è¦ä¸€å¹¶åˆ—å‡ºçš„å…¶ä»–æŒ‡æ ‡:", metrics_available, default=metrics_available[:4] if len(metrics_available) >= 4 else metrics_available, key="tab2_metrics")
            
            t2_sorted = bench_pivot.sort_values(by=t2_metric, ascending=False).reset_index()
            t2_models_selected = st.multiselect(
                "éœ€è¦æ”¾å…¥è¡¨æ ¼å¯¹æ¯”çš„æ¨¡å‹ (ç•™ç©ºä»£è¡¨æ˜¾ç¤ºæ‰€æœ‰):",
                t2_sorted['Model'].tolist(),
                default=[]
            )
            
            display_cols = [t2_metric] + [m for m in t2_metrics if m != t2_metric]
            
            if t2_models_selected:
                display_df = bench_pivot.loc[t2_models_selected, display_cols].sort_values(by=t2_metric, ascending=False)
            else:
                display_df = bench_pivot.loc[:, display_cols].sort_values(by=t2_metric, ascending=False)
                
            st.dataframe(display_df.style.format("{:.3f}", na_rep='-'), use_container_width=True)
    
    # --- Tab 3: Arena ç«æŠ€æ’å ---
    with tab3:
        st.markdown("### Arena æ’è¡Œæ¦œ")
        st.caption("æ•°æ®æº: arena.ai Â· ç”±çœŸäººç›²æµ‹å¯¹æˆ˜çš„ ELO åˆ†æ•°")
        
        if df_lmarena is None or df_lmarena.empty:
            st.warning("æš‚æœªå‘ç° Arena æ’è¡Œæ¦œæ•°æ®ã€‚")
        else:
            latest_lm_date = df_lmarena['Date'].max()
            st.info(f"æ•°æ®æ›´æ–°äº: **{latest_lm_date.strftime('%Y-%m-%d')}**")
            
            df_latest_lm = df_lmarena[df_lmarena['Date'] == latest_lm_date].copy()
            
            # ä¸¤å¤§ç±»æ•°æ®ï¼šELO æ’è¡Œæ¦œ + Arena Overview
            arena_sub1, arena_sub2 = st.tabs(["ğŸ† ELO æ’è¡Œæ¦œ", "ğŸ“Š Arena Overview"])
            
            # ---- ELO æ’è¡Œæ¦œå­æ ‡ç­¾ ----
            with arena_sub1:
                ELO_LABELS = {
                    'Score_text': 'æ–‡æœ¬ (Text)',
                    'Score_code': 'ä»£ç  (Code)',
                    'Score_vision': 'è§†è§‰ (Vision)',
                    'Score_text_to_image': 'æ–‡ç”Ÿå›¾ (Text-to-Image)',
                    'Score_image_edit': 'å›¾åƒç¼–è¾‘ (Image Edit)',
                    'Score_search': 'æœç´¢ (Search)',
                    'Score_text_to_video': 'æ–‡ç”Ÿè§†é¢‘ (Text-to-Video)',
                    'Score_image_to_video': 'å›¾ç”Ÿè§†é¢‘ (Image-to-Video)',
                }
                
                elo_options = {}
                for col_key, label in ELO_LABELS.items():
                    if col_key in df_latest_lm.columns and df_latest_lm[col_key].notna().sum() > 0:
                        elo_options[label] = col_key
                
                if not elo_options:
                    st.info("æš‚æ—  ELO æ’è¡Œæ•°æ®ã€‚")
                else:
                    selected_elo_label = st.selectbox("é€‰æ‹©æ’è¡Œæ¦œ:", list(elo_options.keys()), index=0, key="arena_elo_cat")
                    selected_elo_col = elo_options[selected_elo_label]
                    
                    ranked_df = df_latest_lm.dropna(subset=[selected_elo_col]).copy()
                    ranked_df = ranked_df.sort_values(selected_elo_col, ascending=False).reset_index(drop=True)
                    
                    # Votes åˆ—
                    votes_col = selected_elo_col.replace('Score_', 'Votes_')
                    
                    if not ranked_df.empty:
                        top_n = min(25, len(ranked_df))
                        top_df = ranked_df.head(top_n).copy()
                        top_df['ELO'] = top_df[selected_elo_col].astype(int)
                        
                        tooltip_fields = ['Model', alt.Tooltip('ELO:Q', title='ELO åˆ†æ•°')]
                        if votes_col in top_df.columns:
                            top_df['Votes'] = top_df[votes_col].fillna(0).astype(int)
                            tooltip_fields.append(alt.Tooltip('Votes:Q', title='æŠ•ç¥¨æ•°', format=','))
                        
                        chart_elo = alt.Chart(top_df).mark_bar(
                            cornerRadiusTopRight=3, cornerRadiusBottomRight=3
                        ).encode(
                            y=alt.Y('Model:N', 
                                    sort=alt.EncodingSortField(field='ELO', order='descending'),
                                    title=None, 
                                    axis=alt.Axis(labelOverlap=False)),
                            x=alt.X('ELO:Q', title='ELO åˆ†æ•°', scale=alt.Scale(zero=False)),
                            color=alt.value('#4C78A8'),
                            tooltip=tooltip_fields
                        ).properties(height=max(300, top_n * 28))
                        st.altair_chart(chart_elo, use_container_width=True)
                        
                        # è¡¨æ ¼
                        disp_cols = ['Model', selected_elo_col]
                        disp_names = {'Model': 'æ¨¡å‹', selected_elo_col: 'ELO åˆ†æ•°'}
                        if votes_col in ranked_df.columns:
                            disp_cols.append(votes_col)
                            disp_names[votes_col] = 'æŠ•ç¥¨æ•°'
                        display_lm = ranked_df[disp_cols].copy()
                        display_lm.rename(columns=disp_names, inplace=True)
                        st.dataframe(display_lm, use_container_width=True, hide_index=True, height=400)
                    else:
                        st.info("è¯¥æ’è¡Œæ¦œæš‚æ— æ•°æ®ã€‚")
            
            # ---- Arena Overview å­æ ‡ç­¾ ----
            with arena_sub2:
                RANK_LABELS = {
                    'Rank_Overall': 'ç»¼åˆ (Overall)',
                    'Rank_Expert': 'ä¸“å®¶ (Expert)',
                    'Rank_Hard_Prompts': 'å›°éš¾æç¤ºè¯',
                    'Rank_Coding': 'ä»£ç ',
                    'Rank_Math': 'æ•°å­¦',
                    'Rank_Creative_Writing': 'åˆ›æ„å†™ä½œ',
                    'Rank_Instruction_Following': 'æŒ‡ä»¤éµå¾ª',
                    'Rank_Longer_Query': 'é•¿æŸ¥è¯¢',
                }
                
                rank_options = {}
                for col_key, label in RANK_LABELS.items():
                    if col_key in df_latest_lm.columns and df_latest_lm[col_key].notna().sum() > 0:
                        rank_options[label] = col_key
                
                if not rank_options:
                    st.info("æš‚æ—  Arena Overview æ•°æ®ã€‚")
                else:
                    selected_rank_label = st.selectbox("æ’åºç»´åº¦:", list(rank_options.keys()), index=0, key="arena_ov_cat")
                    selected_rank_col = rank_options[selected_rank_label]
                    
                    ov_df = df_latest_lm.dropna(subset=[selected_rank_col]).copy()
                    ov_df = ov_df.sort_values(selected_rank_col, ascending=True).reset_index(drop=True)
                    
                    if not ov_df.empty:
                        top_n = min(30, len(ov_df))
                        top_df = ov_df.head(top_n).copy()
                        top_df['æ’å'] = top_df[selected_rank_col].astype(int)
                        
                        chart_ov = alt.Chart(top_df).mark_bar(
                            cornerRadiusTopRight=3, cornerRadiusBottomRight=3
                        ).encode(
                            y=alt.Y('Model:N',
                                    sort=alt.EncodingSortField(field='æ’å', order='ascending'),
                                    title=None,
                                    axis=alt.Axis(labelOverlap=False)),
                            x=alt.X('æ’å:Q', title='æ’å (è¶Šå°è¶Šå¥½)', scale=alt.Scale(reverse=True)),
                            color=alt.value('#E45756'),
                            tooltip=['Model', alt.Tooltip('æ’å:Q', title='æ’å')]
                        ).properties(height=max(300, top_n * 25))
                        st.altair_chart(chart_ov, use_container_width=True)
                        
                        # å¤šç»´åº¦æ’åè¡¨
                        st.markdown(f"#### Arena Overview å®Œæ•´æ’å (å…± {len(ov_df)} ä¸ªæ¨¡å‹)")
                        rank_cols_available = [c for c in RANK_LABELS.keys() if c in ov_df.columns]
                        display_ov = ov_df[['Model'] + rank_cols_available].copy()
                        rename_map = {'Model': 'æ¨¡å‹'}
                        rename_map.update({k: RANK_LABELS[k] for k in rank_cols_available})
                        display_ov.rename(columns=rename_map, inplace=True)
                        st.dataframe(display_ov, use_container_width=True, hide_index=True, height=500)
                    else:
                        st.info("è¯¥ç»´åº¦æš‚æ— æ•°æ®ã€‚")
    
    st.markdown("---")
    col_dl1, col_dl2 = st.columns(2)
    if df_bench is not None:
        with col_dl1:
            data, name, mime, label = get_dataset_download(df_bench, "openrouter_benchmark_full")
            st.download_button(label="ä¸‹è½½ AA Benchmark æ•°æ®", data=data, file_name=name, mime=mime)
    if df_lmarena is not None:
        with col_dl2:
            data, name, mime, label = get_dataset_download(df_lmarena, "lmarena_leaderboard_full")
            st.download_button(label="ä¸‹è½½ LMARENA æ•°æ®", data=data, file_name=name, mime=mime)

# ========================================================
# é¡µé¢ 8: å•æ¨¡å‹æ·±åº¦æ¢ç´¢
# ========================================================
elif page == NAV_SINGLE_MODEL:
    st.subheader("å•æ¨¡å‹åˆ†æ")
    st.caption("ç»¼åˆç”¨é‡ã€åŸºå‡†æµ‹è¯•å’Œå®šä»·æ•°æ®ï¼Œè¿½è¸ªå•ä¸€æ¨¡å‹ã€‚")

    # è·å–åŒ…å«è¿‡å»ç°åœ¨æ‰€æœ‰è®°å½•ä¸‹æ¥çš„åå­—é›†åˆï¼Œç»Ÿä¸€æ¶ˆé™¤é‡åå¹²æ‰°é¡¹
    raw_models = set(all_model_names) | set(all_pricing_models) | set(all_benchmark_models)
    normalized_map = {}
    for rm in raw_models:
        norm = normalize_model_name(rm)
        if norm not in normalized_map:
            normalized_map[norm] = []
        normalized_map[norm].append(rm)
        
    all_possible_models = sorted(list(normalized_map.keys()))
    
    if not all_possible_models:
        st.warning("æš‚æœªå‘ç°ä»»ä½•æ¨¡å‹æ•°æ®ã€‚")
    else:
        selected_model_norm = st.selectbox("é€‰æ‹©æ¨¡å‹:", all_possible_models)
        st.markdown("---")
        
        real_names = normalized_map[selected_model_norm]
        
        # 1. ç´¯è®¡ç”¨é‡è¶‹åŠ¿
        st.markdown("### ç´¯è®¡ç”¨é‡è¶‹åŠ¿")
        if df is not None and not df.empty:
            m_df = df[df['Model'].isin(real_names) | df['Display_Name'].isin(real_names)].sort_values('Date').copy()
                
            if not m_df.empty:
                m_df = m_df.groupby('Date', as_index=False)['Total_Tokens'].sum()
                m_df['Cumulative_Tokens'] = m_df['Total_Tokens'].cumsum()
                
                col_m1, col_m2 = st.columns(2)
                recent_7d = m_df.tail(7)['Total_Tokens'].sum()
                col_m1.metric("ç´¯è®¡æ¶ˆè€—", f"{m_df['Cumulative_Tokens'].iloc[-1]:.4f} Billion")
                col_m2.metric("è¿‘ 7 å¤©æ¶ˆè€—", f"{recent_7d:.4f} Billion")
                    
                chart_cum = alt.Chart(m_df).mark_area(
                    opacity=0.6, 
                    color=alt.Gradient(
                        gradient='linear',
                        stops=[alt.GradientStop(color='orange', offset=0), alt.GradientStop(color='white', offset=1)],
                        x1=1, x2=1, y1=1, y2=0
                    )
                ).encode(
                    x=alt.X('Date:T', title='æ—¥æœŸ'),
                    y=alt.Y('Cumulative_Tokens:Q', title='ç´¯è®¡ Tokens (Billion)'),
                    tooltip=['Date', 'Cumulative_Tokens', 'Total_Tokens']
                ).properties(height=350)
                st.altair_chart(chart_cum, use_container_width=True)
            else:
                st.info("è¯¥æ¨¡å‹æš‚æ—  Token æ¶ˆè€—è®°å½•ã€‚")
        else:
            st.info("æœªè¿æ¥åˆ° Token æ•°æ®æºã€‚")

        st.markdown("---")
        
        # 2. åŸºå‡†æµ‹è¯•è·‘åˆ†
        st.markdown(f"### {selected_model_norm} åŸºå‡†æµ‹è¯•è·‘åˆ†")
        st.caption("åŒä¸€æ¨¡å‹å¯èƒ½æœ‰ Reasoning / Non-Reasoning ç­‰å˜ä½“ã€‚")
        if df_bench is not None and not df_bench.empty:
            latest_bench_date = df_bench['Date'].max()
            df_latest_bench = df_bench[(df_bench['Date'] == latest_bench_date) & (df_bench['Metric'].notna())].copy()
            
            bench_model_cols = [col for col in df_latest_bench.columns if col not in ['Date', 'Metric']]
            matched_b_cols = fuzzy_match_model(selected_model_norm, bench_model_cols, threshold=0.55)
            
            if matched_b_cols:
                tabs_b = st.tabs(matched_b_cols)
                
                for i, m_col in enumerate(matched_b_cols):
                    with tabs_b[i]:
                        model_scores = df_latest_bench[['Metric', m_col]].dropna()
                        if not model_scores.empty:
                            rank_data = []
                            for _, row in model_scores.iterrows():
                                metric = row['Metric']
                                score = row[m_col]
                                
                                all_scores_flat = df_latest_bench[df_latest_bench['Metric'] == metric].drop(columns=['Date', 'Metric']).iloc[0].dropna()
                                all_scores_num = pd.to_numeric(all_scores_flat, errors='coerce').dropna()
                                
                                if score in all_scores_num.values:
                                    rank = all_scores_num.rank(method='min', ascending=False)[m_col]
                                    total = len(all_scores_num)
                                    percentile = (total - rank) / total * 100
                                    
                                    rank_data.append({
                                        'æŒ‡æ ‡': metric,
                                        'å¾—åˆ†': f"{score:.3f}",
                                        'æ’å': f"ç¬¬ {int(rank)} / å…± {total}",
                                        'åˆ†ä½æ•°': f"è¶…è¶Š {percentile:.1f}%"
                                    })
                            
                            if rank_data:
                                st.dataframe(pd.DataFrame(rank_data), use_container_width=True, hide_index=True)
                            else:
                                st.info("æš‚æ— å¯ç”¨æµ‹è¯•æ•°æ®ã€‚")
                        else:
                            st.info("æš‚æ— æ•°æ®ã€‚")
            else:
                st.info("è¯¥æ¨¡å‹æœªè¢«æ”¶å½•äº Benchmark æ•°æ®ä¸­ã€‚")
        else:
            st.info("æœªè¿æ¥åˆ°è·‘åˆ†æ•°æ®æºã€‚")

        st.markdown("---")
        
        # 3. å®šä»·åˆ†æï¼ˆåŒå›¾ï¼šæœ‰æ•ˆä»·æ ¼è¶‹åŠ¿ + å„ä¾›åº”å•†ä»·æ ¼æŸ±çŠ¶å›¾ï¼‰
        st.markdown("### å®šä»·åˆ†æ")
        if df_price is not None and not df_price.empty:
            m_price_df = df_price[df_price['Model'].isin(real_names)].copy()
            if not m_price_df.empty:
                latest_pricing_date = m_price_df['Date'].max()
                df_latest_prices = m_price_df[m_price_df['Date'] == latest_pricing_date]
                
                wa_row = df_latest_prices[df_latest_prices['Provider'] == 'Weighted Average']
                if not wa_row.empty:
                    wa = wa_row.iloc[0]
                    st.success(f"æœ‰æ•ˆå‡ä»·: Input **${wa['Input_Price_1M']:.4f}**/1M Â· Output **${wa['Output_Price_1M']:.4f}**/1M")
                
                # å›¾1: æœ‰æ•ˆä»·æ ¼è¶‹åŠ¿
                st.markdown("#### æœ‰æ•ˆä»·æ ¼è¶‹åŠ¿")
                wa_hist = m_price_df[m_price_df['Provider'] == 'Weighted Average'].copy()
                if not wa_hist.empty:
                    wa_hist['Date'] = pd.to_datetime(wa_hist['Date'])
                    wa_long = wa_hist.melt(
                        id_vars=['Date'],
                        value_vars=['Input_Price_1M', 'Output_Price_1M'],
                        var_name='Type', value_name='Price'
                    ).dropna(subset=['Price'])
                    wa_long['Type'] = wa_long['Type'].map({'Input_Price_1M': 'Input', 'Output_Price_1M': 'Output'})
                    
                    chart_wa = alt.Chart(wa_long).mark_line(point=True).encode(
                        x=alt.X('Date:T', title='æ—¶é—´', axis=alt.Axis(format='%m/%d')),
                        y=alt.Y('Price:Q', title='ä»·æ ¼ ($/1M Tokens)'),
                        color=alt.Color('Type:N', title='ç±»å‹'),
                        tooltip=['Date:T', 'Type', alt.Tooltip('Price:Q', format='$.4f')]
                    ).properties(height=250)
                    st.altair_chart(chart_wa, use_container_width=True)
                
                # å›¾2: å„ä¾›åº”å•† Input ä»·æ ¼è¶‹åŠ¿
                st.markdown("#### å„ä¾›åº”å•† Input ä»·æ ¼è¶‹åŠ¿")
                provider_history = m_price_df[m_price_df['Provider'] != 'Weighted Average'].copy()
                if not provider_history.empty:
                    provider_history['Date'] = pd.to_datetime(provider_history['Date'])
                    
                    chart_input = alt.Chart(provider_history).mark_line(point=True).encode(
                        x=alt.X('Date:T', title='æ—¶é—´', axis=alt.Axis(format='%m/%d')),
                        y=alt.Y('Input_Price_1M:Q', title='Input ä»·æ ¼ ($/1M Tokens)'),
                        color=alt.Color('Provider:N', title='ä¾›åº”å•†', scale=alt.Scale(scheme='tableau20')),
                        tooltip=['Date:T', 'Provider', alt.Tooltip('Input_Price_1M:Q', format='$.4f')]
                    ).properties(height=250)
                    st.altair_chart(chart_input, use_container_width=True)
                else:
                    st.info("æš‚æ— ä¾›åº”å•† Input ä»·æ ¼è¶‹åŠ¿æ•°æ®ã€‚")
                
                # å›¾3: å„ä¾›åº”å•† Output ä»·æ ¼è¶‹åŠ¿
                st.markdown("#### å„ä¾›åº”å•† Output ä»·æ ¼è¶‹åŠ¿")
                if not provider_history.empty:
                    chart_output = alt.Chart(provider_history).mark_line(point=True).encode(
                        x=alt.X('Date:T', title='æ—¶é—´', axis=alt.Axis(format='%m/%d')),
                        y=alt.Y('Output_Price_1M:Q', title='Output ä»·æ ¼ ($/1M Tokens)'),
                        color=alt.Color('Provider:N', title='ä¾›åº”å•†', scale=alt.Scale(scheme='tableau20')),
                        tooltip=['Date:T', 'Provider', alt.Tooltip('Output_Price_1M:Q', format='$.4f')]
                    ).properties(height=250)
                    st.altair_chart(chart_output, use_container_width=True)
                else:
                    st.info("æš‚æ— ä¾›åº”å•† Output ä»·æ ¼è¶‹åŠ¿æ•°æ®ã€‚")
                
                # ä¾›åº”å•†è¯¦æƒ…è¡¨æ ¼
                st.markdown("#### ä¾›åº”å•†è¯¦æƒ… (æœ€æ–°)")
                provider_prices = df_latest_prices[df_latest_prices['Provider'] != 'Weighted Average'].sort_values('Input_Price_1M')
                if not provider_prices.empty:
                    st.dataframe(
                        provider_prices[['Provider', 'Input_Price_1M', 'Output_Price_1M', 'Cache_Hit_Rate']].style.format({
                            'Input_Price_1M': '${:.4f}',
                            'Output_Price_1M': '${:.4f}',
                            'Cache_Hit_Rate': '{:.1%}'
                        }),
                        use_container_width=True,
                        hide_index=True
                    )
            else:
                st.info("æš‚æ— è¯¥æ¨¡å‹çš„å®šä»·æ•°æ®ã€‚")
        else:
            st.info("æœªè¿æ¥åˆ°å®šä»·æ•°æ®æºã€‚")

        st.markdown("---")

        # 4. Arena (LMARENA) æ’å
        st.markdown(f"### {selected_model_norm} çš„ Arena æ’å")
        if df_lmarena is not None and not df_lmarena.empty:
            latest_lm_date = df_lmarena['Date'].max()
            df_latest_lm = df_lmarena[df_lmarena['Date'] == latest_lm_date]
            
            lm_all_models = df_latest_lm['Model'].unique().tolist()
            matched_lm = fuzzy_match_model(selected_model_norm, lm_all_models, threshold=0.5)
            
            if matched_lm:
                lm_rows = df_latest_lm[df_latest_lm['Model'].isin(matched_lm)].copy()
                
                score_cols = [c for c in lm_rows.columns if c.startswith('Score_')]
                rank_cols = [c for c in lm_rows.columns if c.startswith('Rank_')]
                SCORE_LABELS = {
                    'Score_text': 'æ–‡æœ¬', 'Score_code': 'ä»£ç ', 'Score_vision': 'è§†è§‰',
                    'Score_text_to_image': 'æ–‡ç”Ÿå›¾', 'Score_image_edit': 'å›¾åƒç¼–è¾‘', 
                    'Score_search': 'æœç´¢', 'Score_text_to_video': 'æ–‡ç”Ÿè§†é¢‘', 
                    'Score_image_to_video': 'å›¾ç”Ÿè§†é¢‘',
                }
                RANK_LABELS = {
                    'Rank_Overall': 'ç»¼åˆ', 'Rank_Expert': 'ä¸“å®¶', 'Rank_Hard_Prompts': 'å›°éš¾æç¤ºè¯',
                    'Rank_Coding': 'ä»£ç ', 'Rank_Math': 'æ•°å­¦', 'Rank_Creative_Writing': 'åˆ›æ„å†™ä½œ',
                    'Rank_Instruction_Following': 'æŒ‡ä»¤éµå¾ª', 'Rank_Longer_Query': 'é•¿æŸ¥è¯¢',
                }
                
                rank_display = []
                for _, row in lm_rows.iterrows():
                    entry = {'æ¨¡å‹': row['Model']}
                    for rc in rank_cols:
                        label = RANK_LABELS.get(rc, rc)
                        if pd.notna(row.get(rc)):
                            entry[f'{label}æ’å'] = int(row[rc])
                    for sc in score_cols:
                        label = SCORE_LABELS.get(sc, sc)
                        if pd.notna(row.get(sc)):
                            entry[f'{label} ELO'] = int(row[sc])
                    rank_display.append(entry)
                
                if rank_display:
                    st.dataframe(pd.DataFrame(rank_display), use_container_width=True, hide_index=True)
                else:
                    st.info("æœªæ‰¾åˆ°è¯¥æ¨¡å‹çš„æ’åæ•°æ®ã€‚")
            else:
                st.info("è¯¥æ¨¡å‹æš‚æœªè¢« Arena æ”¶å½•ã€‚")
        else:
            st.info("æœªè¿æ¥åˆ° Arena æ•°æ®æºã€‚")
