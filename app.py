import streamlit as st
import pandas as pd
import altair as alt
import os
import io

# === 1. åŸºç¡€é…ç½® ===
st.set_page_config(page_title="OpenRouter æ¨¡å‹è¿½è¸ª", layout="wide")
DATA_FILE = "history_database.csv"

# é¡µé¢æ ‡é¢˜
st.title("OpenRouter æ¨¡å‹è¿½è¸ªçœ‹æ¿")
st.caption("å•ä½: Billion Tokens (åäº¿)")

# å®šä¹‰é¡µé¢åç§°å¸¸é‡
NAV_TN_DAILY = "T+N æ¨ªå‘å¯¹æ¯” (æ¯æ—¥æ¶ˆè€—)"
NAV_CUMULATIVE_COMPARE = "å¤šæ¨¡å‹ç´¯è®¡å¢é•¿ (è¶‹åŠ¿å¯¹æ¯”)"
NAV_DETAIL_DAILY = "å•æ¨¡å‹æ¯æ—¥è¯¦æƒ… (è¶‹åŠ¿åˆ†æ)"
NAV_RAW_DATA = "åŸå§‹æ•°æ®æ£€æŸ¥"
NAV_DAILY_BRIEF = "æ¯æ—¥é€Ÿè§ˆ"

# === 2. å·¥å…·å‡½æ•° ===

@st.cache_data(ttl=600)
def load_data():
    if not os.path.exists(DATA_FILE):
        return None, f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶ `{DATA_FILE}`ï¼Œè¯·ç­‰å¾…çˆ¬è™«è¿è¡Œã€‚"
    try:
        df = pd.read_csv(DATA_FILE)
        if df.empty: return None, "CSV æ–‡ä»¶ä¸ºç©º"
        df['Date'] = pd.to_datetime(df['Date'])
        
        # åç§°æ¸…æ´—ï¼šå»æ‰ '/' å‰é¢çš„å‚å•†å
        df['Display_Name'] = df['Model'].apply(lambda x: x.split('/')[-1] if '/' in x else x)
        
        return df, None
    except Exception as e:
        return None, str(e)

# Excel/CSV æ™ºèƒ½å¯¼å‡ºå‡½æ•°
def get_dataset_download(df, filename_prefix):
    try:
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='Sheet1')
        data = output.getvalue()
        file_name = f"{filename_prefix}.xlsx"
        mime = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        label = "ğŸ“¥ ä¸‹è½½ Excel æ–‡ä»¶ (.xlsx)"
    except ImportError:
        data = df.to_csv(index=False).encode('utf-8-sig')
        file_name = f"{filename_prefix}.csv"
        mime = "text/csv"
        label = "ğŸ“¥ ä¸‹è½½ CSV æ–‡ä»¶ (Excelå…¼å®¹)"
    
    return data, file_name, mime, label

df, error = load_data()
if error:
    st.error(error)
    st.stop()

# === 3. ä¾§è¾¹æ å¯¼èˆª ===
st.sidebar.title("å¯¼èˆª")
page = st.sidebar.radio("é€‰æ‹©è§†å›¾", [
    NAV_DAILY_BRIEF,
    NAV_TN_DAILY,
    NAV_CUMULATIVE_COMPARE,
    NAV_DETAIL_DAILY,
    NAV_RAW_DATA
])

all_model_names = df['Display_Name'].unique()

# æ•°æ®æ¦‚è§ˆé¢æ¿
st.sidebar.divider()
st.sidebar.markdown("#### ğŸ“Š æ•°æ®æ¦‚è§ˆ")
st.sidebar.metric("è¿½è¸ªæ¨¡å‹æ•°", len(all_model_names))
st.sidebar.caption(
    f"ğŸ“… æ•°æ®åŒºé—´: {df['Date'].min().strftime('%Y-%m-%d')} ~ {df['Date'].max().strftime('%Y-%m-%d')}"
)

# ========================================================
# é¡µé¢ 1: T+N æ¨ªå‘å¯¹æ¯” (æ¯æ—¥æ¶ˆè€—)
# ========================================================
if page == NAV_TN_DAILY:
    st.subheader("æ¨¡å‹å¢é•¿æ›²çº¿å¯¹æ¯” (T+N æ¯æ—¥æ¶ˆè€—)")
    st.info("æ¨ªè½´ï¼šä¸Šçº¿å¤©æ•° | çºµè½´ï¼šå½“æ—¥ Token æ¶ˆè€—é‡")

    selected_names = st.multiselect(
        "é€‰æ‹©è¦å¯¹æ¯”çš„æ¨¡å‹:", 
        all_model_names, 
        default=all_model_names[:1] 
    )
    
    if selected_names:
        tn_data = []
        standard_ticks = [0, 1, 2, 3, 4, 5, 6, 7, 10, 14, 30, 60]
        final_tick_values = set(standard_ticks)
        
        max_days_global = 0

        for name in selected_names:
            m_df = df[df['Display_Name'] == name].sort_values('Date')
            if m_df.empty: continue
            
            start_date = m_df.iloc[0]['Date']
            st.caption(f"ğŸ“… **{name}** æ”¶å½•èµ·å§‹æ—¥: {start_date.strftime('%Y-%m-%d')}")
            
            if len(m_df) > 1: m_df = m_df.iloc[:-1]

            latest_date = m_df.iloc[-1]['Date']
            latest_day_diff = (latest_date - start_date).days
            final_tick_values.add(latest_day_diff)
            
            if latest_day_diff > max_days_global:
                max_days_global = latest_day_diff

            for _, row in m_df.iterrows():
                day_diff = (row['Date'] - start_date).days
                if day_diff in standard_ticks or day_diff == latest_day_diff:
                    tn_data.append({
                        'Model': name,
                        'Days_Since_Start': day_diff,
                        'Total_Tokens': row['Total_Tokens'],
                        'Label': f"T+{day_diff}" if day_diff != latest_day_diff else f"Latest (T+{day_diff})",
                        'Real_Date': row['Date'].strftime('%Y-%m-%d')
                    })
        
        if tn_data:
            df_tn = pd.DataFrame(tn_data)
            
            # ã€é…è‰²ä¼˜åŒ–ã€‘ä½¿ç”¨ tableau10 é«˜å¯¹æ¯”é…è‰²
            chart = alt.Chart(df_tn).mark_line(
                point=alt.OverlayMarkDef(size=100, filled=True, color="white", strokeWidth=2)
            ).encode(
                x=alt.X(
                    'Days_Since_Start', 
                    title='ä¸Šçº¿å¤©æ•° (Days)',
                    axis=alt.Axis(values=list(final_tick_values), labelFontSize=20, titleFontSize=24, grid=True),
                    scale=alt.Scale(domain=[0, max_days_global + 1], clamp=True)
                ),
                y=alt.Y(
                    'Total_Tokens', 
                    title='Total Tokens (Billion)',
                    axis=alt.Axis(labelFontSize=20, titleFontSize=24)
                ),
                # å…³é”®ä¿®æ”¹ï¼šscale=alt.Scale(scheme='tableau10')
                color=alt.Color('Model', 
                                scale=alt.Scale(scheme='tableau10'), 
                                legend=alt.Legend(title="æ¨¡å‹åç§°", orient='bottom')),
                tooltip=['Model', 'Label', 'Total_Tokens', 'Real_Date']
            ).properties(height=500)
            
            st.altair_chart(chart, use_container_width=True)
            
            st.markdown("#### ğŸ“‹ æ•°æ®æ˜ç»†")
            df_pivot = df_tn.pivot_table(index='Model', columns='Days_Since_Start', values='Total_Tokens')
            df_pivot.columns = [f"T+{c}" for c in df_pivot.columns]
            st.dataframe(df_pivot.style.format("{:.4f} B"), use_container_width=True)
            
            data, name, mime, label = get_dataset_download(df_pivot.reset_index(), "tn_daily_comparison")
            st.download_button(label=label, data=data, file_name=name, mime=mime)

# ========================================================
# é¡µé¢ 2: å¤šæ¨¡å‹ç´¯è®¡å¢é•¿ (è¶‹åŠ¿å¯¹æ¯”)
# ========================================================
elif page == NAV_CUMULATIVE_COMPARE:
    st.subheader("å¤šæ¨¡å‹ç´¯è®¡å¢é•¿å¯¹æ¯”")
    
    selected_names = st.multiselect(
        "é€‰æ‹©è¦å¯¹æ¯”çš„æ¨¡å‹:", 
        all_model_names, 
        default=all_model_names[:3] if len(all_model_names) >=3 else all_model_names
    )

    if selected_names:
        plot_data = []
        max_day_plot = 0
        
        cols = st.columns(len(selected_names))
        for idx, name in enumerate(selected_names):
            m_df_temp = df[df['Display_Name'] == name].sort_values('Date')
            if not m_df_temp.empty:
                s_date = m_df_temp.iloc[0]['Date'].strftime('%Y-%m-%d')
                cols[idx].caption(f"ğŸ“… **{name}**: {s_date}")

        for name in selected_names:
            m_df = df[df['Display_Name'] == name].sort_values('Date')
            m_df['Cum_Tokens'] = m_df['Total_Tokens'].cumsum()
            if len(m_df) > 1: m_df = m_df.iloc[:-1]
            if m_df.empty: continue

            start_date = m_df.iloc[0]['Date']
            current_max_day = (m_df.iloc[-1]['Date'] - start_date).days
            if current_max_day > max_day_plot:
                max_day_plot = current_max_day

            for _, row in m_df.iterrows():
                day_num = (row['Date'] - start_date).days
                plot_data.append({
                    'Model': name, 'Day': day_num,
                    'Date': row['Date'].strftime('%Y-%m-%d'),
                    'Cumulative_Tokens': row['Cum_Tokens']
                })

        if plot_data:
            df_plot = pd.DataFrame(plot_data)

            # ã€é…è‰²ä¼˜åŒ–ã€‘ä½¿ç”¨ tableau10 é«˜å¯¹æ¯”é…è‰²
            base = alt.Chart(df_plot).encode(
                x=alt.X('Day', title="ä¸Šçº¿å¤©æ•° (Daily)", 
                        scale=alt.Scale(domain=[0, max_day_plot + 2], clamp=True),
                        axis=alt.Axis(labelFontSize=16, titleFontSize=18, grid=True)),
                y=alt.Y('Cumulative_Tokens', title='ç´¯è®¡ Token (Billion)', 
                        axis=alt.Axis(labelFontSize=16, titleFontSize=18)),
                # å…³é”®ä¿®æ”¹ï¼šscale=alt.Scale(scheme='tableau10')
                color=alt.Color('Model', 
                                title='æ¨¡å‹åç§°', 
                                scale=alt.Scale(scheme='tableau10'),
                                legend=alt.Legend(orient='bottom')),
                tooltip=['Model', 'Day', 'Date', 'Cumulative_Tokens']
            )
            chart = (base.mark_line(strokeWidth=3) + base.mark_circle(size=60)).properties(height=600)
            
            st.altair_chart(chart, use_container_width=True)

            st.markdown("### ğŸ“… ç´¯è®¡æ•°å€¼æ˜ç»†")
            df_pivot = df_plot.pivot_table(index='Day', columns='Model', values='Cumulative_Tokens')
            st.dataframe(df_pivot.style.format("{:.4f} B"), use_container_width=True)

            data, name, mime, label = get_dataset_download(df_pivot.reset_index(), "cumulative_growth")
            st.download_button(label=label, data=data, file_name=name, mime=mime)

# ========================================================
# é¡µé¢ 3: å•æ¨¡å‹æ¯æ—¥è¯¦æƒ… (è¶‹åŠ¿åˆ†æ + æ—¥æœŸç­›é€‰)
# ========================================================
elif page == NAV_DETAIL_DAILY:
    st.subheader("å•æ¨¡å‹æ¯æ—¥è¯¦æƒ…è¶‹åŠ¿")
    
    selected_name = st.selectbox("é€‰æ‹©æ¨¡å‹", all_model_names)
    m_df_full = df[df['Display_Name'] == selected_name].sort_values('Date')
    
    if not m_df_full.empty:
        min_date = m_df_full['Date'].min().date()
        max_date = m_df_full['Date'].max().date()
        st.success(f"ğŸ“… **{selected_name}** æ•°æ®æ”¶å½•åŒºé—´: {min_date} è‡³ {max_date}")

        col_filter1, col_filter2 = st.columns([1, 3])
        with col_filter1:
            date_range = st.date_input(
                "ğŸ” ç­›é€‰æ—¶é—´æ®µ",
                value=(min_date, max_date),
                min_value=min_date,
                max_value=max_date
            )
        
        if len(date_range) == 2:
            start_filter, end_filter = date_range
            mask = (m_df_full['Date'].dt.date >= start_filter) & (m_df_full['Date'].dt.date <= end_filter)
            m_df = m_df_full.loc[mask]
        else:
            m_df = m_df_full

        if not m_df.empty:
            latest = m_df.iloc[-1]
            c1, c2, c3 = st.columns(3)
            c1.metric("é€‰æ®µæœ€æ–°æ—¥æœŸ", latest['Date'].strftime('%Y-%m-%d'))
            c2.metric("å½“æ—¥æ¶ˆè€—", f"{latest['Total_Tokens']:.4f} B")
            if latest.get('Reasoning', 0) > 0 and latest.get('Completion', 0) > 0:
                ratio = (latest['Reasoning'] / latest['Completion']) * 100
                c3.metric("Reasoning å æ¯”", f"{ratio:.1f}%")
            else:
                c3.metric("Prompt Tokens", f"{latest['Prompt']:.4f} B")

            chart = alt.Chart(m_df).mark_line(point=True).encode(
                x=alt.X('Date', title='æ—¥æœŸ', axis=alt.Axis(format='%m-%d')),
                y=alt.Y('Total_Tokens', title='Token (Billion)'),
                tooltip=['Date', 'Total_Tokens', 'Prompt', 'Completion']
            )
            
            st.altair_chart(chart, use_container_width=True)
            
            display_cols = ['Date', 'Total_Tokens', 'Prompt', 'Completion', 'Reasoning']
            valid_cols = [c for c in display_cols if c in m_df.columns]
            st.dataframe(m_df[valid_cols].sort_values('Date', ascending=False).style.format({'Total_Tokens':'{:.4f}'}), use_container_width=True)

            data, name, mime, label = get_dataset_download(m_df[valid_cols], f"{selected_name}_daily")
            st.download_button(label=label, data=data, file_name=name, mime=mime)
        else:
            st.warning("âš ï¸ æ‰€é€‰æ—¶é—´æ®µå†…æ— æ•°æ®ã€‚")

# ========================================================
# é¡µé¢ 4: åŸå§‹æ•°æ®æ£€æŸ¥
# ========================================================
elif page == NAV_RAW_DATA:
    st.subheader("æ•°æ®åº“åŸå§‹æ•°æ®")
    
    st.markdown("#### ğŸ’¾ å…¨é‡æ•°æ®ä¸‹è½½")
    data, name, mime, label = get_dataset_download(df, "full_history_database")
    st.download_button(label=label, data=data, file_name=name, mime=mime)
    
    st.divider()
    
    check_name = st.selectbox("é€‰æ‹©è¦æ£€æŸ¥çš„æ¨¡å‹:", all_model_names)
    filtered_df = df[df['Display_Name'] == check_name].sort_values('Date', ascending=False)
    
    st.dataframe(
        filtered_df.style.format({
            'Prompt': '{:.6f} B', 'Completion': '{:.6f} B', 
            'Reasoning': '{:.6f} B', 'Total_Tokens': '{:.6f} B'
        }), use_container_width=True
    )

# ========================================================
# é¡µé¢ 5: æ¯æ—¥é€Ÿè§ˆä¸åˆ†æ
# ========================================================
elif page == NAV_DAILY_BRIEF:
    st.subheader("æ¨¡å‹è¡¨ç°é€Ÿè§ˆä¸åˆ†ææŠ¥å‘Š")
    st.caption("åŸºäºå†å²æ•°æ®çš„å¤šç»´åº¦é‡åŒ–åˆ†æï¼Œæ‰€æœ‰æŒ‡æ ‡å‡ç”±æ•°æ®è‡ªåŠ¨è®¡ç®—ç”Ÿæˆã€‚")

    # --- é¢„è®¡ç®—æ‰€æœ‰æ¨¡å‹çš„æŒ‡æ ‡ ---
    latest_date = df['Date'].max()
    two_weeks_ago = latest_date - pd.Timedelta(days=14)
    seven_days_ago = latest_date - pd.Timedelta(days=7)

    metrics_list = []
    for name in all_model_names:
        m_df = df[df['Display_Name'] == name].sort_values('Date')
        if m_df.empty:
            continue
        # å»æ‰æœ€åä¸€å¤©ï¼ˆå½“å¤©æœªç»“ç®—æ•°æ®ï¼Œå’Œå…¶ä»–é¡µé¢é€»è¾‘ä¿æŒä¸€è‡´ï¼‰
        if len(m_df) > 1:
            m_df = m_df.iloc[:-1]
        if m_df.empty:
            continue

        first_date = m_df.iloc[0]['Date']
        last_date = m_df.iloc[-1]['Date']
        days_online = max((last_date - first_date).days, 1)
        cumulative = m_df['Total_Tokens'].sum()
        daily_avg = cumulative / days_online
        peak = m_df['Total_Tokens'].max()

        # è¿‘ 7 æ—¥å¢é€Ÿ
        recent_df = m_df[m_df['Date'] >= seven_days_ago]
        recent_days = max(len(recent_df), 1)
        recent_avg = recent_df['Total_Tokens'].sum() / recent_days if not recent_df.empty else 0

        # å¢é•¿åŠ¨é‡
        momentum = (recent_avg / daily_avg) if daily_avg > 0 else 0

        metrics_list.append({
            'Model': name,
            'First_Date': first_date,
            'Last_Date': last_date,
            'Days_Online': days_online,
            'Cumulative': round(cumulative, 4),
            'Daily_Avg': round(daily_avg, 4),
            'Recent_7d_Avg': round(recent_avg, 4),
            'Momentum': round(momentum, 2),
            'Peak': round(peak, 4),
        })

    df_metrics = pd.DataFrame(metrics_list)

    if df_metrics.empty:
        st.warning("æš‚æ— å¯åˆ†æçš„æ¨¡å‹æ•°æ®ã€‚")
        st.stop()

    # è®¡ç®—ç™¾åˆ†ä½æ’åï¼ˆä¾›åç»­æ¨¡å—ä½¿ç”¨ï¼‰
    df_metrics['Pct_Rank_DailyAvg'] = df_metrics['Daily_Avg'].rank(pct=True)

    # ============================
    # æ¨¡å— A: è¿‘ä¸¤å‘¨æ–°å¢æ¨¡å‹ä¸€è§ˆ
    # ============================
    st.markdown("---")
    st.markdown("### è¿‘ä¸¤å‘¨æ–°å¢æ¨¡å‹ä¸€è§ˆ")
    st.caption(f"ç»Ÿè®¡åŒºé—´: {two_weeks_ago.strftime('%Y-%m-%d')} ~ {latest_date.strftime('%Y-%m-%d')}")

    new_models_df = df_metrics[df_metrics['First_Date'] >= two_weeks_ago].sort_values('First_Date', ascending=False)

    if new_models_df.empty:
        st.info("è¿‡å»ä¸¤å‘¨å†…æ²¡æœ‰æ–°ä¸Šçº¿çš„æ¨¡å‹ã€‚")
    else:
        st.markdown(f"è¿‡å»ä¸¤å‘¨å…±ä¸Šçº¿ **{len(new_models_df)}** ä¸ªæ–°æ¨¡å‹ã€‚")
        display_new = new_models_df[['Model', 'First_Date', 'Days_Online', 'Cumulative', 'Daily_Avg']].copy()
        display_new.columns = ['æ¨¡å‹åç§°', 'ä¸Šçº¿æ—¥æœŸ', 'ä¸Šçº¿å¤©æ•°', 'ç´¯è®¡æ¶ˆè€— (B)', 'æ—¥å‡æ¶ˆè€— (B)']
        display_new['ä¸Šçº¿æ—¥æœŸ'] = display_new['ä¸Šçº¿æ—¥æœŸ'].dt.strftime('%Y-%m-%d')
        st.dataframe(
            display_new.style.format({'ç´¯è®¡æ¶ˆè€— (B)': '{:.4f}', 'æ—¥å‡æ¶ˆè€— (B)': '{:.4f}'}),
            use_container_width=True, hide_index=True
        )

    # ============================
    # æ¨¡å— B (åŸ D): æ–°æ¨¡å‹ç´¯è®¡å¢é•¿å¯¹æ¯”
    # ============================
    if not new_models_df.empty:
        st.markdown("---")
        st.markdown("### æ–°æ¨¡å‹ç´¯è®¡å¢é•¿å¯¹æ¯”")

        new_model_names = new_models_df['Model'].tolist()
        plot_new = []
        max_day_new = 0

        for name in new_model_names:
            m_df = df[df['Display_Name'] == name].sort_values('Date')
            m_df['Cum_Tokens'] = m_df['Total_Tokens'].cumsum()
            if len(m_df) > 1:
                m_df = m_df.iloc[:-1]
            if m_df.empty:
                continue
            start_date = m_df.iloc[0]['Date']
            current_max = (m_df.iloc[-1]['Date'] - start_date).days
            if current_max > max_day_new:
                max_day_new = current_max
            for _, row in m_df.iterrows():
                day_n = (row['Date'] - start_date).days
                plot_new.append({
                    'Model': name, 'Day': day_n,
                    'Date': row['Date'].strftime('%Y-%m-%d'),
                    'Cumulative_Tokens': row['Cum_Tokens']
                })

        if plot_new:
            df_plot_new = pd.DataFrame(plot_new)
            base_new = alt.Chart(df_plot_new).encode(
                x=alt.X('Day', title='ä¸Šçº¿å¤©æ•°',
                        scale=alt.Scale(domain=[0, max_day_new + 2], clamp=True),
                        axis=alt.Axis(labelFontSize=14, titleFontSize=16, grid=True)),
                y=alt.Y('Cumulative_Tokens', title='ç´¯è®¡ Token (Billion)',
                        axis=alt.Axis(labelFontSize=14, titleFontSize=16)),
                color=alt.Color('Model', title='æ¨¡å‹',
                                scale=alt.Scale(scheme='tableau10'),
                                legend=alt.Legend(orient='bottom')),
                tooltip=['Model', 'Day', 'Date', 'Cumulative_Tokens']
            )
            chart_new = (base_new.mark_line(strokeWidth=3) + base_new.mark_circle(size=60)).properties(height=500)
            st.altair_chart(chart_new, use_container_width=True)
        else:
            st.info("æ–°æ¨¡å‹æš‚æ— è¶³å¤Ÿæ•°æ®ç»˜åˆ¶è¶‹åŠ¿å›¾ã€‚")

    # ============================
    # æ¨¡å— C: åˆ†ææ‘˜è¦ (è¡¨æ ¼åŒ–)
    # ============================
    st.markdown("---")
    st.markdown("### ç»¼åˆåˆ†ææ‘˜è¦")
    st.caption(f"åˆ†æåŸºå‡†æ—¥: {latest_date.strftime('%Y-%m-%d')}")

    # Top 3 ç´¯è®¡æ¶ˆè€—
    with st.expander("ç´¯è®¡æ¶ˆè€— Top 3", expanded=True):
        top3_cum = df_metrics.nlargest(3, 'Cumulative').copy()
        top3_cum['Rank'] = range(1, len(top3_cum) + 1)
        display_top3 = top3_cum[['Rank', 'Model', 'Cumulative', 'Days_Online', 'Daily_Avg']].copy()
        display_top3.columns = ['æ’å', 'æ¨¡å‹', 'ç´¯è®¡æ¶ˆè€— (B)', 'ä¸Šçº¿å¤©æ•°', 'æ—¥å‡æ¶ˆè€— (B)']
        st.dataframe(
            display_top3.style.format({'ç´¯è®¡æ¶ˆè€— (B)': '{:.4f}', 'æ—¥å‡æ¶ˆè€— (B)': '{:.4f}'}),
            use_container_width=True, hide_index=True
        )

    # è¿‘ 7 æ—¥å¢é€Ÿæœ€å¿«
    with st.expander("è¿‘7æ—¥å¢é€Ÿé¢†å…ˆ (Top 3)", expanded=True):
        top3_recent = df_metrics.nlargest(3, 'Recent_7d_Avg').copy()
        top3_recent['Rank'] = range(1, len(top3_recent) + 1)
        display_recent = top3_recent[['Rank', 'Model', 'Recent_7d_Avg']].copy()
        display_recent.columns = ['æ’å', 'æ¨¡å‹', 'è¿‘7æ—¥æ—¥å‡æ¶ˆè€— (B)']
        st.dataframe(
            display_recent.style.format({'è¿‘7æ—¥æ—¥å‡æ¶ˆè€— (B)': '{:.4f}'}),
            use_container_width=True, hide_index=True
        )

    # åŠ é€Ÿå¢é•¿ä¸­çš„æ¨¡å‹
    with st.expander("æ­£åœ¨åŠ é€Ÿå¢é•¿ (åŠ¨é‡ > 1.2)", expanded=True):
        accel = df_metrics[df_metrics['Momentum'] >= 1.2].sort_values('Momentum', ascending=False)
        if not accel.empty:
            accel['Growth_Pct'] = (accel['Momentum'] - 1) * 100
            display_accel = accel[['Model', 'Momentum', 'Growth_Pct']].head(5).copy()
            display_accel.columns = ['æ¨¡å‹', 'åŠ¨é‡å€¼', 'è¿‘æœŸå¢é€Ÿè¶…å‡ºå‡å€¼ (%)']
            st.dataframe(
                display_accel.style.format({'åŠ¨é‡å€¼': '{:.2f}', 'è¿‘æœŸå¢é€Ÿè¶…å‡ºå‡å€¼ (%)': '+{:.0f}%'}),
                use_container_width=True, hide_index=True
            )
        else:
            st.info("æš‚æ— æ˜æ˜¾åŠ é€Ÿå¢é•¿çš„æ¨¡å‹ã€‚")

    # å¢é€Ÿæ”¾ç¼“çš„æ¨¡å‹
    with st.expander("å¢é€Ÿæ”¾ç¼“å…³æ³¨ (åŠ¨é‡ < 0.8)", expanded=True):
        decel = df_metrics[(df_metrics['Momentum'] <= 0.8) & (df_metrics['Days_Online'] >= 7)].sort_values('Momentum')
        if not decel.empty:
            decel['Slowdown_Pct'] = (1 - decel['Momentum']) * 100
            display_decel = decel[['Model', 'Momentum', 'Slowdown_Pct']].head(5).copy()
            display_decel.columns = ['æ¨¡å‹', 'åŠ¨é‡å€¼', 'è¿‘æœŸå¢é€Ÿä½äºå‡å€¼ (%)']
            st.dataframe(
                display_decel.style.format({'åŠ¨é‡å€¼': '{:.2f}', 'è¿‘æœŸå¢é€Ÿä½äºå‡å€¼ (%)': '-{:.0f}%'}),
                use_container_width=True, hide_index=True
            )
        else:
            st.info("æš‚æ— æ˜æ˜¾å¢é€Ÿæ”¾ç¼“çš„æ¨¡å‹ã€‚")

    # æ–°æ¨¡å‹é€Ÿè¯„ï¼ˆä½¿ç”¨ç™¾åˆ†ä½æ’åäº”çº§åˆ¶ï¼‰
    if not new_models_df.empty:
        with st.expander("æ–°æ¨¡å‹åˆæœŸè¡¨ç°è¯„çº§", expanded=True):
            rating_data = []
            for row in new_models_df.itertuples():
                pct_rank = row.Pct_Rank_DailyAvg
                if pct_rank >= 0.90:
                    tier, desc = "S Â· å¤´éƒ¨æ°´å¹³", f"è¶…è¿‡ {pct_rank*100:.0f}% æ¨¡å‹"
                elif pct_rank >= 0.75:
                    tier, desc = "A Â· è¡¨ç°ä¼˜å¼‚", f"è¶…è¿‡ {pct_rank*100:.0f}% æ¨¡å‹"
                elif pct_rank >= 0.50:
                    tier, desc = "B Â· ä¸­ç­‰æ°´å¹³", "æ—¥å‡ > ä¸­ä½æ•°"
                elif pct_rank >= 0.25:
                    tier, desc = "C Â· ä½äºé¢„æœŸ", f"ä»…è¶… {pct_rank*100:.0f}% æ¨¡å‹"
                else:
                    tier, desc = "D Â· èµ·æ­¥ç¼“æ…¢", f"å {(1-pct_rank)*100:.0f}% åˆ†ä½"
                
                rating_data.append({
                    'æ¨¡å‹': row.Model,
                    'ä¸Šçº¿æ—¥æœŸ': row.First_Date.strftime('%m-%d'),
                    'æ—¥å‡æ¶ˆè€— (B)': row.Daily_Avg,
                    'è¯„çº§': tier,
                    'è¯´æ˜': desc
                })
            
            df_rating = pd.DataFrame(rating_data)
            st.dataframe(
                df_rating.style.format({'æ—¥å‡æ¶ˆè€— (B)': '{:.4f}'}),
                use_container_width=True, hide_index=True
            )

    # ============================
    # æ¨¡å— D (åŸ B): å…¨æ¨¡å‹è¡¨ç°æ’å (ç§»è‡³æœ€å)
    # ============================
    st.markdown("---")
    st.markdown("### å…¨æ¨¡å‹è¡¨ç°æ’å (Top 15)")

    RANK_OPTIONS = {
        'ç´¯è®¡æ€»é‡': 'Cumulative',
        'æ—¥å‡æ¶ˆè€—': 'Daily_Avg',
        'è¿‘7æ—¥å¢é€Ÿ': 'Recent_7d_Avg',
        'å¢é•¿åŠ¨é‡': 'Momentum',
        'å³°å€¼æ¶ˆè€—': 'Peak',
        'ä¸Šçº¿å¤©æ•°': 'Days_Online'
    }
    col_rank1, col_rank2 = st.columns([1, 3])
    with col_rank1:
        rank_label = st.selectbox("é€‰æ‹©æ’åç»´åº¦", list(RANK_OPTIONS.keys()))
    rank_col = RANK_OPTIONS[rank_label]

    df_ranked = df_metrics.sort_values(rank_col, ascending=False).head(15).reset_index(drop=True)
    df_ranked.index = df_ranked.index + 1

    chart_rank = alt.Chart(df_ranked).mark_bar(
        cornerRadiusTopLeft=4, cornerRadiusTopRight=4
    ).encode(
        x=alt.X('Model', sort='-y', title='æ¨¡å‹',
                axis=alt.Axis(labelAngle=-45, labelFontSize=11)),
        y=alt.Y(rank_col, title=rank_label,
                axis=alt.Axis(labelFontSize=14, titleFontSize=16)),
        color=alt.Color('Model', legend=None, scale=alt.Scale(scheme='tableau10')),
        tooltip=['Model', alt.Tooltip(rank_col, title=rank_label, format='.4f')]
    ).properties(height=400)
    st.altair_chart(chart_rank, use_container_width=True)

    display_ranked = df_ranked[['Model', 'Days_Online', 'Cumulative', 'Daily_Avg', 'Recent_7d_Avg', 'Momentum', 'Peak']].copy()
    display_ranked.columns = ['æ¨¡å‹', 'ä¸Šçº¿å¤©æ•°', 'ç´¯è®¡ (B)', 'æ—¥å‡ (B)', 'è¿‘7æ—¥å‡ (B)', 'åŠ¨é‡', 'å³°å€¼ (B)']

    def highlight_momentum(val):
        if isinstance(val, (int, float)):
            if val >= 1.2:
                return 'background-color: #d4edda; color: #155724'
            elif val <= 0.8:
                return 'background-color: #f8d7da; color: #721c24'
        return ''

    st.dataframe(
        display_ranked.style
            .format({'ç´¯è®¡ (B)': '{:.4f}', 'æ—¥å‡ (B)': '{:.4f}', 'è¿‘7æ—¥å‡ (B)': '{:.4f}', 'åŠ¨é‡': '{:.2f}', 'å³°å€¼ (B)': '{:.4f}'})
            .map(highlight_momentum, subset=['åŠ¨é‡']),
        use_container_width=True, hide_index=False
    )
    st.caption("åŠ¨é‡ > 1.2 (ç»¿è‰²èƒŒæ™¯) = åŠ é€Ÿå¢é•¿ Â· åŠ¨é‡ < 0.8 (çº¢è‰²èƒŒæ™¯) = å¢é€Ÿæ”¾ç¼“")

    # ============================
    # æ¨¡å— E: è¿‘ä¸¤å‘¨æ–°æ¨¡å‹åŠ¨æ€ (RSS)
    # ============================
    st.markdown("---")
    st.markdown("### è¿‘ä¸¤å‘¨æ–°æ¨¡å‹åŠ¨æ€")

    if new_models_df.empty:
        st.info("è¿‘ä¸¤å‘¨å†…æ— æ–°ä¸Šçº¿æ¨¡å‹ï¼Œæš‚æ— ç›¸å…³æ–°é—»å¯æ£€ç´¢ã€‚")
    else:
        import re as _re
        import requests as _requests


        # â”€â”€ AI ä¸“ä¸šåª’ä½“ RSS æº â”€â”€
        RSS_FEEDS = [
            ("TechCrunch AI",   "https://techcrunch.com/category/artificial-intelligence/feed/"),
            ("VentureBeat AI",  "https://venturebeat.com/category/ai/feed/"),
            ("The Verge AI",    "https://www.theverge.com/rss/ai-artificial-intelligence/index.xml"),
            ("Ars Technica",    "https://feeds.arstechnica.com/arstechnica/technology-lab"),
        ]

        # â”€â”€ ä»æ¨¡å‹å…¨åæå–å“ç‰Œå â”€â”€
        def extract_brand(full_name):
            base = full_name.split('/')[-1]
            return base.split('-')[0].lower()

        # â”€â”€ è‡ªåŠ¨æ‰“æ ‡ç­¾ï¼šè¿”å›åŒ¹é…çš„å“ç‰Œåï¼Œæ— åŒ¹é…è¿”å› None â”€â”€
        def detect_tag(text, brand_label_map):
            text_lower = text.lower()
            for brand, label in brand_label_map.items():
                if brand in text_lower:
                    return label
            return None

        # â”€â”€ æ„å»ºå“ç‰Œåæ ‡ç­¾æ˜ å°„ï¼ˆRSS æ¥æºæœ¬èº«æ˜¯ AI åª’ä½“ï¼Œä¸éœ€è¦è¿‡æ»¤çŸ­è¯ï¼‰â”€â”€
        model_names_raw = new_models_df['Model'].tolist()
        brand_label_map = {}
        for full_name in model_names_raw:
            brand = extract_brand(full_name)
            if brand and len(brand) >= 3:
                brand_label_map[brand] = brand
        # è¡¥å……å¸¸è§å‚å•†åˆ«åï¼Œæé«˜å¬å›ç‡
        ALIAS_MAP = {"gpt": "openai", "o1": "openai", "o3": "openai", "step": "stepfun"}
        for short, full in ALIAS_MAP.items():
            if short in brand_label_map:
                brand_label_map[full] = full

        cutoff = latest_date - pd.Timedelta(days=14)
        cutoff_str = cutoff.strftime('%Y-%m-%d')

        # â”€â”€ ç¿»è¯‘å‡½æ•°ï¼ˆç¼“å­˜ 24 å°æ—¶ï¼‰â”€â”€
        @st.cache_data(ttl=86400)
        def translate_zh(text):
            if not text or not text.strip():
                return text
            try:
                from deep_translator import GoogleTranslator
                return GoogleTranslator(source='en', target='zh-CN').translate(text[:500])
            except Exception:
                return text

        # â”€â”€ æŠ“å–å¹¶è§£æ RSSï¼ˆç¼“å­˜ 3 å°æ—¶ï¼Œä½¿ç”¨ feedparserï¼‰â”€â”€
        @st.cache_data(ttl=10800)
        def fetch_rss_articles(cutoff_str):
            import feedparser
            cutoff_dt = pd.Timestamp(cutoff_str, tz='UTC')
            results = []
            for feed_name, feed_url in RSS_FEEDS:
                try:
                    feed = feedparser.parse(feed_url)
                    for entry in feed.entries:
                        title = entry.get('title', '').strip()
                        link  = entry.get('link', '#')
                        # æ‘˜è¦ï¼šä¼˜å…ˆ summaryï¼Œå…¶æ¬¡ content
                        desc_raw = entry.get('summary', '') or ''
                        if not desc_raw and entry.get('content'):
                            desc_raw = entry['content'][0].get('value', '')
                        import re as _re2
                        desc = _re2.sub(r'<[^>]+>', '', desc_raw).strip()[:300]
                        # å‘å¸ƒæ—¶é—´ï¼šfeedparser ç»Ÿä¸€è§£æä¸º time.struct_time
                        pub_parsed = entry.get('published_parsed') or entry.get('updated_parsed')
                        if pub_parsed:
                            pub_dt = pd.Timestamp(*pub_parsed[:6], tz='UTC')
                        else:
                            pub_dt = pd.Timestamp.now(tz='UTC')
                        if pub_dt < cutoff_dt:
                            continue
                        results.append({
                            'title': title, 'desc': desc, 'link': link,
                            'source': feed_name, 'date': pub_dt.strftime('%Y-%m-%d'),
                        })
                except Exception:
                    continue
            results.sort(key=lambda x: x['date'], reverse=True)
            return results


        brand_display = ', '.join(list(brand_label_map.keys())[:8])
        st.caption(f"æ•°æ®æ¥æº: TechCrunch / VentureBeat / The Verge / Ars Technica Â· æ¯3å°æ—¶æ›´æ–° Â· åŒ¹é…å“ç‰Œ: {brand_display}")

        all_articles = fetch_rss_articles(cutoff_str)

        # â”€â”€ è¿‡æ»¤å‡ºä¸æ–°æ¨¡å‹ç›¸å…³çš„æ–‡ç«  â”€â”€
        matched = []
        for art in all_articles:
            tag = detect_tag(f"{art['title']} {art['desc']}", brand_label_map)
            if tag is not None:
                art['tag'] = tag
                matched.append(art)

        if not matched:
            st.info("è¿‘ä¸¤å‘¨å†… AI åª’ä½“ä¸­æœªæ‰¾åˆ°è¿™äº›æ¨¡å‹çš„ç›¸å…³æŠ¥é“ã€‚")
        else:
            st.markdown(f"å…±æ‰¾åˆ° **{len(matched)}** æ¡ç›¸å…³æŠ¥é“ï¼ˆæ ‡é¢˜å’Œæ‘˜è¦å·²ç¿»è¯‘ä¸ºä¸­æ–‡ï¼‰")
            for art in matched:
                title_zh = translate_zh(art['title']) if art['title'] else "æ— æ ‡é¢˜"
                desc_zh = translate_zh(art['desc']) if art['desc'] else ""
                with st.expander(
                    f"[{art['tag']}]  {title_zh}  Â·  {art['source']}  Â·  {art['date']}",
                    expanded=False
                ):
                    if desc_zh:
                        st.markdown(desc_zh)
                    st.caption(f"åŸæ–‡: {art['title']}")
                    st.markdown(f"[é˜…è¯»åŸæ–‡ â†’]({art['link']})")



    # ============================
    # æ¨¡å— F: æŒ‡æ ‡å®šä¹‰ä¸å…¬å¼è¯´æ˜
    # ============================
    st.markdown("---")
    st.markdown("### é™„å½•: æŒ‡æ ‡å®šä¹‰ä¸è®¡ç®—å…¬å¼")
    with st.expander("æŸ¥çœ‹å®Œæ•´æŒ‡æ ‡è¯´æ˜", expanded=False):
        st.markdown("""
| æŒ‡æ ‡ | å®šä¹‰ | è®¡ç®—å…¬å¼ |
|------|------|----------|
| **æ—¥å‡æ¶ˆè€—** | æ¨¡å‹å…¨ç”Ÿå‘½å‘¨æœŸå†…å¹³å‡æ¯å¤©çš„ Token æ¶ˆè€—é‡ | `ç´¯è®¡æ€»é‡ Ã· ä¸Šçº¿å¤©æ•°` |
| **è¿‘7æ—¥å¢é€Ÿ** | æœ€è¿‘ 7 ä¸ªè‡ªç„¶æ—¥å†…çš„æ—¥å¹³å‡ Token æ¶ˆè€—é‡ | `Î£(è¿‘7æ—¥ Total_Tokens) Ã· è¿‘7æ—¥æ•°æ®æ¡æ•°` |
| **å¢é•¿åŠ¨é‡** | è¿‘æœŸæ´»è·ƒåº¦ç›¸å¯¹äºå…¨ç”Ÿå‘½å‘¨æœŸå‡å€¼çš„æ¯”ç‡ | `è¿‘7æ—¥å¢é€Ÿ Ã· æ—¥å‡æ¶ˆè€—` |
| **å³°å€¼æ¶ˆè€—** | å†å²å•æ—¥æœ€é«˜ Token æ¶ˆè€—é‡ | `max(æ¯æ—¥ Total_Tokens)` |
| **ç´¯è®¡æ€»é‡** | æ¨¡å‹ä¸Šçº¿ä»¥æ¥æ‰€æœ‰æ—¥æœŸ Token æ¶ˆè€—ä¹‹å’Œ | `Î£(Total_Tokens)` |
| **ä¸Šçº¿å¤©æ•°** | æ¨¡å‹é¦–æ¬¡å‡ºç°åœ¨æ•°æ®åº“åˆ°æœ€æ–°æ•°æ®çš„å¤©æ•° | `æœ€æ–°æ•°æ®æ—¥æœŸ - é¦–æ¬¡å‡ºç°æ—¥æœŸ` |

**åŠ¨é‡è§£è¯»:**
- åŠ¨é‡ = 1.0 â†’ è¿‘æœŸå¢é€Ÿä¸å…¨æœŸå‡å€¼æŒå¹³
- åŠ¨é‡ > 1.2 â†’ è¿‘æœŸå¤„äºåŠ é€Ÿå¢é•¿é˜¶æ®µ
- åŠ¨é‡ < 0.8 â†’ è¿‘æœŸå¢é€Ÿæ”¾ç¼“ï¼Œå¯èƒ½è¿›å…¥è¡°é€€æœŸ

**æ–°æ¨¡å‹è¯„çº§è¯´æ˜:**

è¯„çº§é‡‡ç”¨**ç™¾åˆ†ä½æ’åæ³• (Percentile Rank)**ï¼Œå°†æ–°æ¨¡å‹çš„æ—¥å‡æ¶ˆè€—æ”¾å…¥å…¨éƒ¨æ¨¡å‹çš„æ—¥å‡æ¶ˆè€—åˆ†å¸ƒä¸­è®¡ç®—æ’åç™¾åˆ†ä½:
- `ç™¾åˆ†ä½ = æ—¥å‡æ¶ˆè€— < è¯¥æ¨¡å‹çš„æ¨¡å‹æ•°é‡ Ã· æ€»æ¨¡å‹æ•°`

| è¯„çº§ | ç™¾åˆ†ä½åŒºé—´ | å«ä¹‰ |
|------|-----------|------|
| **S Â· å¤´éƒ¨æ°´å¹³** | â‰¥ P90 | æ—¥å‡æ¶ˆè€—è¶…è¿‡ 90% çš„æ¨¡å‹ï¼Œå±äºé¡¶çº§è¡¨ç° |
| **A Â· è¡¨ç°ä¼˜å¼‚** | P75 ~ P90 | æ—¥å‡æ¶ˆè€—å¤„äºå‰ 25%ï¼Œå¢é•¿åŠ¿å¤´å¼ºåŠ² |
| **B Â· ä¸­ç­‰æ°´å¹³** | P50 ~ P75 | æ—¥å‡æ¶ˆè€—é«˜äºä¸­ä½æ•°ï¼Œè¡¨ç°ä¸­è§„ä¸­çŸ© |
| **C Â· ä½äºé¢„æœŸ** | P25 ~ P50 | æ—¥å‡æ¶ˆè€—å¤„äºä¸­ä½æ•°ä»¥ä¸‹ï¼Œå…³æ³¨åç»­èµ°åŠ¿ |
| **D Â· èµ·æ­¥ç¼“æ…¢** | < P25 | æ—¥å‡æ¶ˆè€—å¤„äºå 25%ï¼Œå¯èƒ½å°šæœªè¢«å¹¿æ³›é‡‡ç”¨ |
""")
